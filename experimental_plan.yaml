name: tcr
version: develop

## 외부에서 데이터 가져오기 / 결과 저장하는 경우 해당 위치에 지정
external_path:
    - load_train_data_path: ./solution/sample_data/train
    - load_inference_data_path:  ./solution/sample_data/test
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
    - load_model_path:

external_path_permission:
    - aws_key_profile: 
 
## 실험에 필요한 파라미터를 설정함 
## - 해당 위치에서 삭제되면, code 의 default 로 실행
user_parameters:
    - train_pipeline:
        - step: input 
          args:
            - file_type: csv
              encoding: utf-8
          ui_args: 
        
        - step: readiness
          args:
            - x_columns: [input_x0,input_x1,input_x2,input_x3]
              y_column: target
              column_types: auto
              task_type: classification
              target_label: _major
          ui_args:
            - x_columns
            - y_column

        - step: preprocess
          args:
            - save_original_columns: True
          ui_args:

        - step: train
          args:
            - evaluation_metric: auto
              shapley_value: True 
              output_type: all
          ui_args:
            - evaluation_metric
            - shapley_value

        - step: output
          args:
          ui_args:

    - inference_pipeline:
        - step: input  
          args:
          ui_args: 
        
        - step: readiness
          args:
          ui_args:

        - step: preprocess
          args:
          ui_args:

        - step: inference
          args:
          ui_args:

        - step: output
          args:
          ui_args:

## asset 의 설치 정보를 기록       
asset_source:
    - train_pipeline:
        - step: input
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/input.git
            # code: local
            branch: v1.0.0_tabular # tabular 
            requirements:
              - pandas==1.5.3

        - step: readiness
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            # code: local
            branch: tcr_dev
            requirements:
              - requirements.txt

        - step: preprocess
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/preps.git
            # code: local
            branch: develop
            requirements:
              - requirements.txt

        - step: train
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/tcr_ml.git
            # code: local
            branch: develop
            requirements:
              - requirements.txt 
    
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            # code: local
            branch: v1.0.0
            requirements:
              - requirements.txt
   
    - inference_pipeline:
        - step: input
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/input.git
            # code: local
            branch: v1.0.0_tabular # tabular 
            requirements:
              - pandas==1.5.3

        - step: readiness
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            # code: local
            branch: tcr_dev
            requirements:
              - requirements.txt

        - step: preprocess
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/preps.git
            # code: local
            branch: develop
            requirements:
              - requirements.txt

        - step: inference
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/tcr_ml.git
            # code: local
            branch: develop
            requirements:
              - requirements.txt 
    
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            # code: local
            branch: v1.0.0
            requirements:
              - requirements.txt
           
     
control:
    ## 1. 패키지 설치 및 asset 존재 여부를 실험 시마다 체크할지, 한번만 할지 결정
    ## 1-2 requirements.txt 및 종속 패키지들 한번만 설치할 지 매번 설치할지도 결정 
    - get_asset_source: once ## once, every
    ## 2. 생성된 artifacts 를 backup 할지를 결정 True/False
    - backup_artifacts: True
    ## 3. pipeline 로그를 backup 할지를 결정 True/False
    - backup_log: True
    ## 4. 저장 공간 사이즈를 결정 (단위 MB)
    - backup_size: 1000
    ## 5. Asset 사이 데이터 전달 방법으로 memory, file 를 지원
    - interface_mode: file

########
ui_args_detail:
    - train_pipeline:
        - step: input 
          args:
              - name: file_type
                description: input data의 파일 확장자를 입력합니다.(현재 AI Solution 등록은 csv만 가능합니다.)
                type: single_selection
                default: csv
                selectable:
                  - csv
              - name: encoding
                description: input data의 encoding type을 입력합니다.(현재 AI Solution 등록은 utf-8만 가능합니다.)
                type: string
                default: utf-8
                range:
                  - 1
                  - 1000000
        - step: readiness 
          args:
              - name: x_columns
                description: Dataframe에 있는 학습 대상 x 컬럼 명을 ','로 구분하여 입력합니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: y_column
                description: Dataframe에 있는 y 컬럼 명을 입력합니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: task_type
                description: Solution 과제의 유형(classification/regression)을 입력합니다.
                type: single_selection
                default: classification
                selectable:
                  - classification
                  - regression
              - name: target_label
                description: classification시 y_column의 어떤 class를 기준으로 모델을 평가할지 정합니다. 여러 class일 경우 ','로 구분하여 입력하세요.
                type: string
                default: _major
                range:
                  - 1
                  - 1000000
              - name: drop_x_columns
                description: dataframe의 전체 컬럼을 학습 대상으로 지정하고, drop_x_columns에 입력한 컬럼을 제외합니다. 컬럼 여러개는 ','로 구분하여 입력하세요.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: groupkey_columns
                description: groupkey 컬럼을 입력하면 해당 컬럼의 value 값을 기준으로 dataframe을 grouping합니다. 컬럼이 여러개면 ','로 구분하여 입력합니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
        - step: preprocess
          args:
              - name: save_original_columns
                description: 전처리 결과 dataframe에 원본 dataframe을 합칠 경우 True를 입력합니다. False일 경우, 전처리한 학습 컬럼만 다음 asset으로 전달됩니다.
                type: single_selection
                default: True
                selectable:
                  - True
                  - False    
        - step: train 
          args:
              - name: evaluation_metric
                description: HPO시 모델을 선택하기 위한 평가 metric을 선택합니다.
                type: single_selection
                default: accuracy
                selectable:
                  - accuracy
                  - f1
                  - recall
                  - precision
                  - mse
                  - r2
                  - mae
                  - rmse    
              - name: shapley_value
                description: shapley value를 계산하여 output.csv에 출력할지 결정합니다.
                type: single_selection
                default: False
                selectable:
                  - False
                  - True
              - name: output_type
                description: output.csv에 전체 컬럼과 모델링 결과 컬럼 전체를 저장할지(all), 모델링 컬럼만 저장할지(simple) 결정합니다.
                type: single_selection
                default: all
                selectable:
                  - all
                  - simple
    - inference_pipeline: