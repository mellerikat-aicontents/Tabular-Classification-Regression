## 외부에서 데이터 가져오기 / 결과 저장하는 경우 해당 위치에 지정
external_path:
    - load_train_data_path: ./solution/sample_data/train/
    - load_inference_data_path: ./solution/sample_data/test/
    - save_train_artifacts_path:
    - save_inference_artifacts_path:

external_path_permission:
    - s3_private_key_file: 
 
## 실험에 필요한 파라미터를 설정함 
## - 해당 위치에서 삭제되면, code 의 default 로 실행
user_parameters:
    - train_pipeline:
        - step: input  ## 필수
          args:
            - input_path: train 
              x_columns: [input_x0, input_x1, input_x2, input_x3]
              use_all_x: False
              y_column: target #TRAIN_LABEL" #label"
              groupkey_columns:
              drop_columns:
              time_column:
              concat_dataframes: True
              encoding: # cp949 
          ui_args: 
            - x_columns
            - y_column

        - step: preprocess
          args:
            - mode: auto # auto, custom
              custom: {}
        
        - step: train ## 필수
          args:
            - model_type: classification ## supproted list: classification, regression
              data_split_method: cross_validate # supproted list: cross_validate, train_test_split
              evaluation_metric: accuracy ## classification: accuracy, precision, recall, f1-score
              model_list: [lgb, rf, cb] # 알고리즘 선택(param_range를 사용할 경우, classification의 경우 rf, gbm, lgb, cb만 가능)
              num_hpo: 3 # HPO 횟수 설정, 0 인 경우 하기 설정을 무시하고 위에서 선택한 알고리즘에 대해서 default로 실행됨
              param_range: {
                rf: {max_depth: 6, n_estimators: [300, 500]},
                gbm: {max_depth: [5, 7], n_estimators: [300, 500]},
                ngb: {col_sample: [0.6, 0.8], n_estimators:[100, 300]},               
                lgb: {max_depth:[5, 9], n_estimators:[300, 500]},
                cb: {max_depth:[5, 9], n_estimators:[100, 500]},
              } # 탐색하고 싶은 parameter [min, max] 설정, 숫자만 입력할 경우 해당 parameter는 고정됨
              ## num_hpo=3, max_depth=[1, 3]인 경우 hpo 과정에서 max_depth가 1, 2, 3인 경우에 대해 실행됨.(소수점인 경우 integer로 실행)
              shap_ratio: 1.
          ui_args:
            - model_type
            - evaluation_metric
            - shap_ratio

        - step: output
          args:


    - inference_pipeline:
        - step: input  ## 필수
          args:
            - input_path: test
              x_columns: [input_x0, input_x1, input_x2, input_x3]
              use_all_x: False
              y_column:  #TRAIN_LABEL" #label"
              groupkey_columns:
              drop_columns:
              time_column:
              concat_dataframes: True
              encoding: # cp949 
          
          ui_args:
            - x_columns

        - step: preprocess
          args:
            - mode: auto # auto, custom
              custom: {}

        - step: inference ## 필수
          args:
            - model_type: classification
              run_shapley: True   
          ui_args:
            - run_shapley

        - step: output
          args:


## asset 의 설치 정보를 기록       
asset_source:
    - train_pipeline:
        - step: input
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/input.git
            # code: local
            branch: tabular_dev_solution # tabular 
            requirements:
              - pandas==1.5.3

        - step: preprocess
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/dxadvtech/assets/preps.git
            # code: local
            branch: prep_dev_solution
            requirements:
              - requirements.txt

        - step: train
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/tcr.git
            # code: local
            branch: tcr_dev_solution
            requirements:
              - requirements.txt 
              - numpy==1.25.2 --force-reinstall
    
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            # code: local
            branch: output_dev
            requirements:
              - requirements.txt
   
    - inference_pipeline:
        - step: input
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/input.git
            # code: local
            branch: tabular_dev_solution #tabular
            requirements:
              - pandas==1.5.3

        - step: preprocess
          source:  ## git / local 지원
            # code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/preprocess.git
            code: local
            branch: prep_dev_solution
            requirements:
              - requirements.txt

        - step: inference
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/tcr.git
            # code: local
            branch: tcr_dev_solution
            requirements:
              - requirements.txt
        
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            # code: local
            branch: output_dev
            requirements:
              - requirements.txt
           
     
control:
    ## 1. 패키지 설치 및 asset 존재 여부를 실험 시마다 체크할지, 한번만 할지 결정
    ## 1-2 requirements.txt 및 종속 패키지들 한번만 설치할 지 매번 설치할지도 결정 
    - get_asset_source: once ## once, every
    ## 1-3 external path로 부터 data load 관련하여 한번만 가져올 지 매번 가져올지 결정 
    - get_external_data: once ## once, every
    ## 2. 생성된 artifacts 를 backup 할지를 결정 True/False
    - backup_artifacts: True
    ## 3. pipeline 로그를 backup 할지를 결정 True/False
    - backup_log: True
    ## 4. 저장 공간 사이즈를 결정 (단위 MB)
    - backup_size: 1000
 
    ## 5. Asset 사이 데이터 전달 방법으로 memory, file 를 지원
    - interface_mode: file

########
ui_args_detail:
    - train_pipeline:
        - step: input 
          args:
              - name: x_columns
                description: TCR 모델링에 사용될 x columns를 ','로 구분하여 기입합니다. ex) x_column1, x_column2
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
 
              - name: y_column
                description: TCR 모델링에 사용될 y column명을 기입합니다. ex) y_column
                type: string
                default: ''
                range:
                  - 1
                  - 1000000

        - step: train
          args:
              - name: model_type
                description: 학습 유형을 선택합니다.
                type: single_selection
                default: classification
                selectable:
                  - classification
                  - regression

              - name: evaluation_metric
                description: TCR 학습 시 best 모델 선정 기준을 선택합니다.
                type: single_selection
                default: accuracy
                selectable:
                  - accuracy
                  - precision
                  - recall
                  - f1-score

              - name: shap_ratio
                description: 학습에 사용된 데이터 중 입력한 비율 만큼 shapley value를 출력합니다.
                type: float
                default: 0.1
                range:
                  - 0.001
                  - 0.99

    - inference_pipeline:
        - step: input 
          args:
              - name: x_columns
                description: TCR 모델링에 사용될 x columns를 ','로 구분하여 기입합니다. ex) x_column1, x_column2
                type: string
                default:
                range:
                  - 1
                  - 1000000

        - step: inference
          args:
              - name: run_shapley
                description: "inference시 shapley value 출력 여부를 결정합니다 (shapley value 출력: True)"
                type: single_selection
                default: True
                selectable:
                  - True
                  - False