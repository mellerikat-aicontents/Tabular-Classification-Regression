{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921781c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alo_module import SimpleALO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d6289",
   "metadata": {},
   "source": [
    "아래는 ALO 기본 설정 및 라이브러리 설치 코드입니다. 설치 에러가 발생하면 아래 셀을 재실행 하고, 지속적으로 문제가 있을 시 문의바랍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce91a6-d23b-4631-92a2-12e15b1b328f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a0c212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 04:20:50,000][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,002][PROCESS][INFO]:  Skip loading external data. << /nas001/users/yoonji.suh/tcr_test_20231016/train_multiclass/ >> \n",
      " << train_multiclass >> already exists in << /home/jovyan/project/alo_dev/tcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,004][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,007][PROCESS][INFO]: << input >> asset had already been created at 2023-11-08 01:28:00.751822\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,008][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,010][PROCESS][INFO]: << preprocess >> asset had already been created at 2023-11-08 01:28:02.002831\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,012][PROCESS][INFO]: Start setting-up << sampling >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,014][PROCESS][INFO]: << sampling >> asset had already been created at 2023-11-08 01:28:04.169848\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,016][PROCESS][INFO]: Start setting-up << train >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,018][PROCESS][INFO]: << train >> asset had already been created at 2023-11-08 01:28:09.861891\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,022][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,024][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,025][PROCESS][INFO]: >>> Ignored installing << numpy==1.25.2 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,027][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,029][PROCESS][INFO]: >>> Ignored installing << scikit-learn >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,032][PROCESS][INFO]: >>> Ignored installing << matplotlib >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,034][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,036][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,039][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,040][PROCESS][INFO]: ======================================== Start dependency installation : << preprocess >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,042][PROCESS][INFO]: Start checking existence & installing package - category_encoders | Progress: ( 2 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,044][PROCESS][INFO]: [OK] << category_encoders >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,046][PROCESS][INFO]: ======================================== Start dependency installation : << sampling >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,047][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 | Progress: ( 3 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,050][PROCESS][INFO]: [OK] << numpy==1.25.2 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,052][PROCESS][INFO]: Start checking existence & installing package - scikit-learn | Progress: ( 4 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,054][PROCESS][INFO]: [OK] << scikit-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,056][PROCESS][INFO]: Start checking existence & installing package - umap-learn | Progress: ( 5 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,058][PROCESS][INFO]: [OK] << umap-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,060][PROCESS][INFO]: Start checking existence & installing package - matplotlib | Progress: ( 6 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,062][PROCESS][INFO]: [OK] << matplotlib >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,064][PROCESS][INFO]: ======================================== Start dependency installation : << train >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,066][PROCESS][INFO]: Start checking existence & installing package - seaborn | Progress: ( 7 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,068][PROCESS][INFO]: [OK] << seaborn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,070][PROCESS][INFO]: Start checking existence & installing package - shap | Progress: ( 8 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,072][PROCESS][INFO]: [OK] << shap >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,075][PROCESS][INFO]: Start checking existence & installing package - lightgbm | Progress: ( 9 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,078][PROCESS][INFO]: [OK] << lightgbm >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,080][PROCESS][INFO]: Start checking existence & installing package - catboost | Progress: ( 10 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,083][PROCESS][INFO]: [OK] << catboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,085][PROCESS][INFO]: Start checking existence & installing package - ngboost | Progress: ( 11 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:20:50,087][PROCESS][INFO]: [OK] << ngboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,089][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,091][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 --force-reinstall | Progress: ( 12 / 12 total packages ) \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:20:50,093][PROCESS][INFO]: >>> Start installing package - numpy==1.25.2 --force-reinstall\u001b[0m\n",
      "Collecting numpy==1.25.2\n",
      "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed numpy-1.25.2\n",
      "\u001b[94m[2023-11-08 04:21:01,369][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Train 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "simalo = SimpleALO(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df61efa",
   "metadata": {},
   "source": [
    "### 1. Input asset \n",
    "##### Input asset의 arguments 수정 및 확인\n",
    "- 필요한경우 input_args의 항목을 ***input_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d044fa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'train_multiclass',\n",
       " 'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       " 'use_all_x': False,\n",
       " 'y_column': 'target',\n",
       " 'groupkey_columns': None,\n",
       " 'drop_columns': None,\n",
       " 'time_column': None,\n",
       " 'concat_dataframes': True,\n",
       " 'encoding': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "input_args = simalo.get_args(step=0)\n",
    "\n",
    "# 아래 주석을 풀어 input_args를 원하는 값으로 수정합니다. \n",
    "# input_args['x_columns'] = ['input_x0','input_x1']\n",
    "input_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa17ca",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f228e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-08 04:21:02,437][USER][INFO][train_pipeline][input]: >> Load path : ['/home/jovyan/project/alo_dev/tcr/alo//input/train_multiclass/']\n",
      "[2023-11-08 04:21:02,453][USER][INFO][train_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/project/alo_dev/tcr/alo//input/train_multiclass/iris.csv)\n",
      "[2023-11-08 04:21:02,457][USER][INFO][train_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-08 04:21:02,461][USER][INFO][train_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[2023-11-08 04:21:02,465][USER][INFO][train_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/project/alo_dev/tcr/alo//input/train_multiclass/iris.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 04:21:02,433][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:02\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_2.0\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_config.pkl\n",
      "\u001b[94m[2023-11-08 04:21:02,471][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:02\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:02,473][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: input\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  input_x0  input_x1  input_x2  input_x3  target\n",
       "0           0       5.1       3.5       1.4       0.2  setosa\n",
       "1           1       4.9       3.0       1.4       0.2  setosa\n",
       "2           2       4.7       3.2       1.3       0.2  setosa\n",
       "3           3       4.6       3.1       1.5       0.2  setosa\n",
       "4           4       5.0       3.6       1.4       0.2  setosa\n",
       "5           5       5.4       3.9       1.7       0.4  setosa\n",
       "6           6       4.6       3.4       1.4       0.3  setosa\n",
       "7           7       5.0       3.4       1.5       0.2  setosa\n",
       "8           8       4.4       2.9       1.4       0.2  setosa\n",
       "9           9       4.9       3.1       1.5       0.1  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simalo.run(args=input_args) # 변경한 input_args 반영\n",
    "\n",
    "# simalo.data: input asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# simalo.config: input asset의 결과 config입니다. 다음 asset실행 시 필요합니다.\n",
    "\n",
    "# input asset의 결과 dataframe은 data_input['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1056a2-0146-4612-b32b-eda9b9eef0eb",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 2. Preprocess asset \n",
    "##### Preprocess asset의 args수정 및 확인\n",
    "- 필요한경우 preprocess_args의 항목을 ***preprocess_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ee6653-d1aa-4f0a-91bc-3bd60c158a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handling_encoding_y_column': 'target',\n",
       " 'handling_encoding_y': 'label',\n",
       " 'handling_missing': 'dropna',\n",
       " 'handling_scaling_x': 'none',\n",
       " 'drop_duplicate_time': True,\n",
       " 'load_train_preprocess': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "preprocess_args = simalo.get_args(step=1)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess_args 수정합니다. \n",
    "# preprocess_args['handling_missing'] = 'interpolation'\n",
    "preprocess_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae00130-ccf8-4ce4-988d-5cc978cb0d28",
   "metadata": {},
   "source": [
    "##### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da6ed5f-5324-4775-b748-f4a8592b6aea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_data.pkl\n",
      "\u001b[92m[2023-11-08 04:21:04,477][ASSET][INFO][train_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:04,478][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:04\n",
      "- current step      : preprocess\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_encoding_y_column', 'handling_encoding_y', 'handling_missing', 'handling_scaling_x', 'drop_duplicate_time', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "target column : label Encoder saved : /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/preprocess/\n",
      "['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'] target_encoded_nan\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_config.pkl\n",
      "\u001b[94m[2023-11-08 04:21:04,526][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:04\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:04,528][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>target</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  input_x2  input_x3  target  target_encoded  \\\n",
       "0       5.1       3.5       1.4       0.2  setosa               0   \n",
       "1       4.9       3.0       1.4       0.2  setosa               0   \n",
       "2       4.7       3.2       1.3       0.2  setosa               0   \n",
       "3       4.6       3.1       1.5       0.2  setosa               0   \n",
       "4       5.0       3.6       1.4       0.2  setosa               0   \n",
       "5       5.4       3.9       1.7       0.4  setosa               0   \n",
       "6       4.6       3.4       1.4       0.3  setosa               0   \n",
       "7       5.0       3.4       1.5       0.2  setosa               0   \n",
       "8       4.4       2.9       1.4       0.2  setosa               0   \n",
       "9       4.9       3.1       1.5       0.1  setosa               0   \n",
       "\n",
       "   input_x0_nan  input_x1_nan  input_x2_nan  input_x3_nan  target_encoded_nan  \n",
       "0           5.1           3.5           1.4           0.2                   0  \n",
       "1           4.9           3.0           1.4           0.2                   0  \n",
       "2           4.7           3.2           1.3           0.2                   0  \n",
       "3           4.6           3.1           1.5           0.2                   0  \n",
       "4           5.0           3.6           1.4           0.2                   0  \n",
       "5           5.4           3.9           1.7           0.4                   0  \n",
       "6           4.6           3.4           1.4           0.3                   0  \n",
       "7           5.0           3.4           1.5           0.2                   0  \n",
       "8           4.4           2.9           1.4           0.2                   0  \n",
       "9           4.9           3.1           1.5           0.1                   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simalo.run(args=preprocess_args) # 변경한 preprocess_args 반영\n",
    "# asset_structure.data: preprocess asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: preprocess asset의 결과 config입니다. 다음 asset실행 시 필요합니다. \n",
    "\n",
    "# preprocess asset의 결과 dataframe은 data_preprocess['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd960780-4d1f-43eb-b28d-561031203f53",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 3. Sampling asset \n",
    "##### Sampling asset의 args수정 및 확인\n",
    "- 필요한경우 Sampling_args의 항목을 ***sampling_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3385afc-3bda-426f-9a33-ac41d0c2288c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sampling_type': 'none',\n",
       " 'sampling_method': 'random',\n",
       " 'label_sampling': False,\n",
       " 'ignore_label_class': None,\n",
       " 'negative_target_class': None,\n",
       " 'label_sampling_num_type': None,\n",
       " 'label_sampling_num': None,\n",
       " 'sampling_groupkey_columns': None,\n",
       " 'sampling_num_type': 'ratio',\n",
       " 'sampling_num': 0.8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "sampling_args = simalo.get_args(step=2)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess_args 수정합니다. \n",
    "# sampling_args['sampling_type'] = 'under'\n",
    "sampling_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fde40b-fb56-47aa-ab6d-4cc95957fe00",
   "metadata": {},
   "source": [
    "##### Sampling asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af2307c-924c-4f26-9c81-d8044b9ba3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/envs/tcr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_data.pkl\n",
      "\u001b[94m[2023-11-08 04:21:15,450][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:15\n",
      "- current step      : sampling\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['sampling_type', 'sampling_method', 'label_sampling', 'ignore_label_class', 'negative_target_class', 'label_sampling_num_type', 'label_sampling_num', 'sampling_groupkey_columns', 'sampling_num_type', 'sampling_num'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:15,452][ASSET][INFO][train_pipeline][sampling]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/sampling/\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_config.pkl\n",
      "\u001b[94m[2023-11-08 04:21:15,457][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:15\n",
      "- current step      : sampling\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:15,460][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: sampling\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>target</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  input_x2  input_x3  target  target_encoded  \\\n",
       "0       5.1       3.5       1.4       0.2  setosa               0   \n",
       "1       4.9       3.0       1.4       0.2  setosa               0   \n",
       "2       4.7       3.2       1.3       0.2  setosa               0   \n",
       "3       4.6       3.1       1.5       0.2  setosa               0   \n",
       "4       5.0       3.6       1.4       0.2  setosa               0   \n",
       "5       5.4       3.9       1.7       0.4  setosa               0   \n",
       "6       4.6       3.4       1.4       0.3  setosa               0   \n",
       "7       5.0       3.4       1.5       0.2  setosa               0   \n",
       "8       4.4       2.9       1.4       0.2  setosa               0   \n",
       "9       4.9       3.1       1.5       0.1  setosa               0   \n",
       "\n",
       "   input_x0_nan  input_x1_nan  input_x2_nan  input_x3_nan  target_encoded_nan  \n",
       "0           5.1           3.5           1.4           0.2                   0  \n",
       "1           4.9           3.0           1.4           0.2                   0  \n",
       "2           4.7           3.2           1.3           0.2                   0  \n",
       "3           4.6           3.1           1.5           0.2                   0  \n",
       "4           5.0           3.6           1.4           0.2                   0  \n",
       "5           5.4           3.9           1.7           0.4                   0  \n",
       "6           4.6           3.4           1.4           0.3                   0  \n",
       "7           5.0           3.4           1.5           0.2                   0  \n",
       "8           4.4           2.9           1.4           0.2                   0  \n",
       "9           4.9           3.1           1.5           0.1                   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simalo.run(args=sampling_args) # 변경한 sampling_args 반영\n",
    "# asset_structure.data: sampling asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: sampling asset의 결과 config입니다. 다음 asset실행 시 필요합니다. \n",
    "\n",
    "# sampling asset의 결과 dataframe은 data_sampling['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24997c79-babb-4445-b1ff-e2493dfdaad6",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 4. train asset \n",
    "##### train asset의 args수정 및 확인\n",
    "- 필요한경우 TCR_args의 항목을 ***TCR_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e0840b-50ba-4f6b-8998-8b28a5bfd5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification',\n",
       " 'data_split_method': 'cross_validate',\n",
       " 'evaluation_metric': 'accuracy',\n",
       " 'model_list': ['lgb', 'rf', 'cb'],\n",
       " 'num_hpo': 3,\n",
       " 'param_range': {'rf': {'max_depth': 6, 'n_estimators': [300, 500]},\n",
       "  'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "  'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "  'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "  'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}},\n",
       " 'shap_ratio': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "tcr_args = simalo.get_args(step=3)\n",
    "\n",
    "# 아래 주석을 풀어 tcr_args를 수정합니다. \n",
    "# tcr_args['model_list'] = ['lgb']\n",
    "tcr_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29407e1f-58b2-4c97-b58a-6d684ad47167",
   "metadata": {},
   "source": [
    "##### train asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e964dac8-836a-4b4c-b2b1-d183377d4068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_data.pkl\n",
      "\u001b[92m[2023-11-08 04:21:20,287][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:20,292][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:20,293][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:20\n",
      "- current step      : train\n",
      "- asset branch.     : main\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'data_split_method', 'evaluation_metric', 'model_list', 'num_hpo', 'param_range', 'shap_ratio'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:20,295][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:20,297][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:20,299][ASSET][INFO][train_pipeline][train]: Successfully got << report path >> for saving your << report.html >> file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/report/\u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['target_encoded', 'target', 'input_x2', 'input_x3', 'input_x0', 'input_x1', 'target_encoded_nan'])\n",
      "[INFO] 모델 학습을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 0th-fold RandomForestClassifier_set0 모델을 학습합니다.(1/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set0 모델을 학습합니다.(2/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set0 모델을 학습합니다.(3/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set0 모델을 학습합니다.(4/36)\n",
      "[INFO] 0th-fold RandomForestClassifier_set1 모델을 학습합니다.(5/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set1 모델을 학습합니다.(6/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set1 모델을 학습합니다.(7/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set1 모델을 학습합니다.(8/36)\n",
      "[INFO] 0th-fold RandomForestClassifier_set2 모델을 학습합니다.(9/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set2 모델을 학습합니다.(10/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set2 모델을 학습합니다.(11/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set2 모델을 학습합니다.(12/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set0 모델을 학습합니다.(13/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set0 모델을 학습합니다.(14/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set0 모델을 학습합니다.(15/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set0 모델을 학습합니다.(16/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set1 모델을 학습합니다.(17/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set1 모델을 학습합니다.(18/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set1 모델을 학습합니다.(19/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set1 모델을 학습합니다.(20/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set2 모델을 학습합니다.(21/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set2 모델을 학습합니다.(22/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set2 모델을 학습합니다.(23/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set2 모델을 학습합니다.(24/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set0 모델을 학습합니다.(25/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set0 모델을 학습합니다.(26/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set0 모델을 학습합니다.(27/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set0 모델을 학습합니다.(28/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set1 모델을 학습합니다.(29/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set1 모델을 학습합니다.(30/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set1 모델을 학습합니다.(31/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set1 모델을 학습합니다.(32/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set2 모델을 학습합니다.(33/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set2 모델을 학습합니다.(34/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set2 모델을 학습합니다.(35/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set2 모델을 학습합니다.(36/36)\n",
      "@scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list:  @scoring_classification func. - label list: @scoring_classification func. - label list:     @scoring_classification func. - label list:  {0, 1, 2} {0, 1, 2}{0, 1, 2} {0, 1, 2} {0, 1, 2}{0, 1, 2}{0, 1, 2}\n",
      "\n",
      "\n",
      "{0, 1, 2}{0, 1, 2}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] 평가 지표는 ( accuracy ) 를 사용합니다. \n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "\n",
      "train_pipeline [['x0', 'input_x0_nan'], ['x1', 'input_x1_nan'], ['x2', 'input_x2_nan'], ['x3', 'input_x3_nan']]\n",
      "\n",
      "\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "모델 정보 로그를 저장합니다. (저장위치: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/model_selection.json)\n",
      "\n",
      "Top 1 model file is saved: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top0.pkl\n",
      "[Score] accuracy: 0.9660\n",
      "[Hyper-parameters] max_depth: 5, n_estimators: 100, verbose: 0, random_state: 1234, thread_count: 6, allow_writing_files: False, \n",
      "\n",
      "Top 2 model file is saved: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top1.pkl\n",
      "[Score] accuracy: 0.9592\n",
      "[Hyper-parameters] max_depth: 5, n_estimators: 300, n_jobs: 1, verbose: -1, \n",
      "\n",
      "Top 3 model file is saved: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top2.pkl\n",
      "[Score] accuracy: 0.9592\n",
      "[Hyper-parameters] max_depth: 7, n_estimators: 400, n_jobs: 1, verbose: -1, \n",
      "\n",
      "Following model is the best: CatBoostClassifier_set0 / accuracy:0.9660\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[INFO] Summary_plot for Train data 를 저장했습니다.\n",
      "\n",
      "ignore columns와 X로 지정한 데이터 프레임을 합치는 과정중에 에러가 발생했습니다. 확인 부탁드립니다.\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/train_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/train_config.pkl\n",
      "\u001b[94m[2023-11-08 04:21:24,819][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:24\n",
      "- current step      : train\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type', 'feature_dict'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:24,822][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "      <th>input_x0_nan_shapley</th>\n",
       "      <th>input_x1_nan_shapley</th>\n",
       "      <th>input_x2_nan_shapley</th>\n",
       "      <th>input_x3_nan_shapley</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "      <th>pred_target_encoded_nan</th>\n",
       "      <th>pred_target_encoded_nan_best0</th>\n",
       "      <th>pred_target_encoded_nan_best1</th>\n",
       "      <th>pred_target_encoded_nan_best2</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.120640</td>\n",
       "      <td>-0.565583</td>\n",
       "      <td>-0.292216</td>\n",
       "      <td>-0.708609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.997956</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.612707</td>\n",
       "      <td>-1.634705</td>\n",
       "      <td>0.184778</td>\n",
       "      <td>-0.882783</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.994512</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.889092</td>\n",
       "      <td>-0.445722</td>\n",
       "      <td>-0.425943</td>\n",
       "      <td>-0.971802</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.633480</td>\n",
       "      <td>-0.240888</td>\n",
       "      <td>-1.250112</td>\n",
       "      <td>-0.993943</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.997316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.595638</td>\n",
       "      <td>-1.436253</td>\n",
       "      <td>0.367625</td>\n",
       "      <td>-0.872879</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.990348</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.960572</td>\n",
       "      <td>-0.319784</td>\n",
       "      <td>-0.278283</td>\n",
       "      <td>-0.895378</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.997874</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.190894</td>\n",
       "      <td>-1.338538</td>\n",
       "      <td>-0.419388</td>\n",
       "      <td>-0.721726</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.191156</td>\n",
       "      <td>-1.224103</td>\n",
       "      <td>-0.279464</td>\n",
       "      <td>-0.715320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.997480</td>\n",
       "      <td>0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.790117</td>\n",
       "      <td>0.971815</td>\n",
       "      <td>1.143319</td>\n",
       "      <td>1.353714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984845</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.471003</td>\n",
       "      <td>-0.833077</td>\n",
       "      <td>-0.322991</td>\n",
       "      <td>-1.216012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>0.992834</td>\n",
       "      <td>0.002301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0_nan  input_x1_nan  input_x2_nan  input_x3_nan  \\\n",
       "0           5.7           2.8           4.1           1.3   \n",
       "1           5.0           2.3           3.3           1.0   \n",
       "2           6.5           2.8           4.6           1.5   \n",
       "3           6.3           2.9           5.6           1.8   \n",
       "4           5.1           2.5           3.0           1.1   \n",
       "5           6.6           3.0           4.4           1.4   \n",
       "6           5.5           2.5           4.0           1.3   \n",
       "7           5.5           2.3           4.0           1.3   \n",
       "8           5.1           3.8           1.9           0.4   \n",
       "9           5.2           2.7           3.9           1.4   \n",
       "\n",
       "   input_x0_nan_shapley  input_x1_nan_shapley  input_x2_nan_shapley  \\\n",
       "0             -0.120640             -0.565583             -0.292216   \n",
       "1              0.612707             -1.634705              0.184778   \n",
       "2             -0.889092             -0.445722             -0.425943   \n",
       "3             -0.633480             -0.240888             -1.250112   \n",
       "4              0.595638             -1.436253              0.367625   \n",
       "5             -0.960572             -0.319784             -0.278283   \n",
       "6             -0.190894             -1.338538             -0.419388   \n",
       "7             -0.191156             -1.224103             -0.279464   \n",
       "8              0.790117              0.971815              1.143319   \n",
       "9              0.471003             -0.833077             -0.322991   \n",
       "\n",
       "   input_x3_nan_shapley  target_encoded_nan  pred_target_encoded_nan  \\\n",
       "0             -0.708609                   1                        1   \n",
       "1             -0.882783                   1                        1   \n",
       "2             -0.971802                   1                        1   \n",
       "3             -0.993943                   2                        2   \n",
       "4             -0.872879                   1                        1   \n",
       "5             -0.895378                   1                        1   \n",
       "6             -0.721726                   1                        1   \n",
       "7             -0.715320                   1                        1   \n",
       "8              1.353714                   0                        0   \n",
       "9             -1.216012                   1                        1   \n",
       "\n",
       "   pred_target_encoded_nan_best0  pred_target_encoded_nan_best1  \\\n",
       "0                              1                              1   \n",
       "1                              1                              1   \n",
       "2                              1                              1   \n",
       "3                              2                              2   \n",
       "4                              1                              1   \n",
       "5                              1                              1   \n",
       "6                              1                              1   \n",
       "7                              1                              1   \n",
       "8                              0                              0   \n",
       "9                              1                              1   \n",
       "\n",
       "   pred_target_encoded_nan_best2    prob_0    prob_1    prob_2  \n",
       "0                              1  0.001300  0.997956  0.000744  \n",
       "1                              1  0.004045  0.994512  0.001443  \n",
       "2                              1  0.000938  0.997803  0.001259  \n",
       "3                              2  0.000972  0.001713  0.997316  \n",
       "4                              1  0.006667  0.990348  0.002985  \n",
       "5                              1  0.001309  0.997874  0.000817  \n",
       "6                              1  0.000867  0.997849  0.001284  \n",
       "7                              1  0.001036  0.997480  0.001484  \n",
       "8                              0  0.984845  0.013084  0.002072  \n",
       "9                              1  0.004865  0.992834  0.002301  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACboAAAMWCAYAAAA9daJ8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLbElEQVR4nOzdeZBW5d3n/w8gNNKAkAhKi0KIjrIZQ7WoiEo0ihHUEsVtjAET44Zr3LIhRdw3QjBPpClGVOwRwfyUFpfouD0ugzomLhFjAkYRIioMICB7//54yp50WtAmDX3E16vKKvvc17mu7337l1XvOqdJdXV1dQAAAAAAAAAAAKCgmjb2AAAAAAAAAAAAALAxQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCN+qloqIia9asaewxAAAAAAAAAACArxChGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAA0Mi6du2aYcOGNfYYhSV0AwAAAAAAAAAA2Exmz56dM844I926dUvLli3Ttm3b7L///hk7dmw++eSTxh7vc61atSqXXXZZysrKsu2222afffbJo48+usXn2GaLnwgAAAAAAAAAAPAFNLlxbWOPkOqLNz2xmjFjRoYOHZqSkpKceuqp6dWrV1avXp1nnnkml1xySf785z+noqKiAadteMOGDcu0adNywQUXZLfddsukSZNyxBFH5Iknnkj//v232BxCNwAAAAAAAAAAgAb29ttv58QTT0yXLl3y+OOPp1OnTjWfnXPOOfnb3/6WGTNmNOKEn++FF17I3XffnRtuuCEXX3xxktQEe5deemmee+65LTaLV5cCAAAAAAAAAAA0sOuvvz7Lli3LxIkTa0Vun9p1111z/vnnb/D+RYsW5eKLL07v3r3TunXrtG3bNt/73vfyyiuv1Fk7bty49OzZM61atUr79u1TXl6eysrKms8//vjjXHDBBenatWtKSkrSsWPHHHrooXn55Zc3+h2mTZuWZs2a5cc//nHNtZYtW+aHP/xhnn/++cydO/eL/BQNwhPdAAAAAAAAAAAAGlhVVVW6deuWfv36bdL9c+bMyX333ZehQ4fmG9/4RhYsWJDx48fnoIMOyhtvvJGysrIkyYQJE3LeeefluOOOy/nnn5+VK1fm1VdfzcyZM3PyyScnSc4888xMmzYtI0aMSI8ePbJw4cI888wzmTVrVvr06bPBGf74xz/mv/23/5a2bdvWut63b98kyZ/+9KfsvPPOm/T96kvoBgAAAAAAAAAA0ICWLl2aefPm5eijj97kPXr37p233norTZv+v5d2fv/7388ee+yRiRMn5pe//GWSZMaMGenZs2emTp26wb1mzJiR008/PTfddFPNtUsvvfRzZ/jHP/7xmU+j+/Ta/Pnzv/D3+Xd5dSkAAAAAAAAAAEADWrp0aZKkTZs2m7xHSUlJTeS2bt26LFy4MK1bt87uu+9e65Wj7dq1y3vvvZcXX3xxg3u1a9cuM2fOrHeY9sknn6SkpKTO9ZYtW9Z8vqUI3QAAAAAAAAAAABrQp6/6/Pjjjzd5j/Xr12fMmDHZbbfdUlJSku233z4dOnTIq6++miVLltSsu+yyy9K6dev07ds3u+22W84555w8++yztfa6/vrr8/rrr2fnnXdO3759M2rUqMyZM+dzZ9h2222zatWqOtdXrlxZ8/mWInQDAAAAAAAAAABoQG3btk1ZWVlef/31Td7j6quvzkUXXZQDDzwwkydPziOPPJJHH300PXv2zPr162vWde/ePX/5y19y9913p3///rn33nvTv3//XHHFFTVrjj/++MyZMyfjxo1LWVlZbrjhhvTs2TMPPfTQRmfo1KlT/vGPf9S5/um1srKyTf5+9SV0AwAAAAAAAAAAaGCDBw/O7Nmz8/zzz2/S/dOmTct3vvOdTJw4MSeeeGIOO+ywfPe7383ixYvrrC0tLc0JJ5yQ2267Le+++24GDRqUq666qubJa8l/RWtnn3127rvvvrz99tv5+te/nquuumqjM+y111556623al7F+qmZM2fWfL6lCN0AAAAAAAAAAAAa2KWXXprS0tL86Ec/yoIFC+p8Pnv27IwdO3aD9zdr1izV1dW1rk2dOjXz5s2rdW3hwoW1/m7RokV69OiR6urqrFmzJuvWrav1qtMk6dixY8rKyj7ztaT/7Ljjjsu6detSUVFRc23VqlW57bbbss8++2TnnXfe6P0NaZstdhIAAAAAAAAAAMBXxDe/+c1UVlbmhBNOSPfu3XPqqaemV69eWb16dZ577rlMnTo1w4YN2+D9gwcPzujRozN8+PD069cvr732Wu66665069at1rrDDjssO+64Y/bff//ssMMOmTVrVm655ZYMGjQobdq0yeLFi9O5c+ccd9xx+da3vpXWrVvnsccey4svvpibbrppo99hn332ydChQ/PTn/40H3zwQXbdddfcfvvt+fvf/56JEyc2xM/0hQndAAAAAAAAAAAANoOjjjoqr776am644Ybcf//9+d3vfpeSkpLsueeeuemmm3L66adv8N6f/exnWb58eSorKzNlypT06dMnM2bMyOWXX15r3RlnnJG77rorN998c5YtW5bOnTvnvPPOyy9+8YskSatWrXL22WfnD3/4Q37/+99n/fr12XXXXfMf//EfOeussz73O9xxxx355S9/mTvvvDP/9//+3+y555554IEHcuCBB/57P049Nan+1+fbwUZUVFRk+PDhad68eWOPAgAAAAAAAAAAfEU0bewBAAAAAAAAAAAAYGOEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAADSyrl27ZtiwYY09RmEJ3QAAAAAAAAAAADaT2bNn54wzzki3bt3SsmXLtG3bNvvvv3/Gjh2bTz75pLHH26gXX3wxI0aMSM+ePVNaWppddtklxx9/fN56660tPss2W/xEAAAAAAAAAACAr4AZM2Zk6NChKSkpyamnnppevXpl9erVeeaZZ3LJJZfkz3/+cyoqKhp7zA267rrr8uyzz2bo0KHZc8898/777+eWW25Jnz598r//9/9Or169ttgsQjcAAAAAAAAAAKCQPuj+/zX2COk465hNuu/tt9/OiSeemC5duuTxxx9Pp06daj4755xz8re//S0zZsxoqDE3i4suuiiVlZVp0aJFzbUTTjghvXv3zrXXXpvJkydvsVm8uhQAAAAAAAAAAKCBXX/99Vm2bFkmTpxYK3L71K677przzz9/g/cvWrQoF198cXr37p3WrVunbdu2+d73vpdXXnmlztpx48alZ8+eadWqVdq3b5/y8vJUVlbWfP7xxx/nggsuSNeuXVNSUpKOHTvm0EMPzcsvv7zR79CvX79akVuS7LbbbunZs2dmzZr1eT9Bg/JENwAAAAAAAAAAgAZWVVWVbt26pV+/fpt0/5w5c3Lfffdl6NCh+cY3vpEFCxZk/PjxOeigg/LGG2+krKwsSTJhwoScd955Oe6443L++edn5cqVefXVVzNz5sycfPLJSZIzzzwz06ZNy4gRI9KjR48sXLgwzzzzTGbNmpU+ffrUa67q6uosWLAgPXv23KTvtamEbgAAAAAAAAAAAA1o6dKlmTdvXo4++uhN3qN3795566230rTp/3tp5/e///3ssccemThxYn75y18mSWbMmJGePXtm6tSpG9xrxowZOf3003PTTTfVXLv00ks3aa677ror8+bNy+jRozfp/k3l1aUAAAAAAAAAAAANaOnSpUmSNm3abPIeJSUlNZHbunXrsnDhwrRu3Tq77757rVeOtmvXLu+9915efPHFDe7Vrl27zJw5M/Pnz9/keZLkzTffzDnnnJP99tsvP/jBD/6tvepL6AYAAAAAAAAAANCA2rZtmyT5+OOPN3mP9evXZ8yYMdltt91SUlKS7bffPh06dMirr76aJUuW1Ky77LLL0rp16/Tt2ze77bZbzjnnnDz77LO19rr++uvz+uuvZ+edd07fvn0zatSozJkzp17zvP/++xk0aFC22267TJs2Lc2aNdvk77YphG4AAAAAAAAAAAANqG3btikrK8vrr7++yXtcffXVueiii3LggQdm8uTJeeSRR/Loo4+mZ8+eWb9+fc267t275y9/+Uvuvvvu9O/fP/fee2/69++fK664ombN8ccfnzlz5mTcuHEpKyvLDTfckJ49e+ahhx76QrMsWbIk3/ve97J48eI8/PDDKSsr2+TvtamaVFdXV2/xU/nSqqioyPDhw9O8efPGHgUAAAAAAAAAgK3cB93/v8YeIR1nHbNJ951xxhmpqKjIc889l/322+9z13ft2jUDBgzIpEmTkiR77bVXvva1r+Xxxx+vta5z587Zdddd8+STT37mPqtXr86QIUPy8MMPZ9myZWnZsmWdNR988EH69OmTrl275plnntnoXCtXrsxhhx2W//N//k8ee+yxL/RdNgdPdAMAAAAAAAAAAGhgl156aUpLS/OjH/0oCxYsqPP57NmzM3bs2A3e36xZs/zrM8ymTp2aefPm1bq2cOHCWn+3aNEiPXr0SHV1ddasWZN169bVetVpknTs2DFlZWVZtWrVRr/DunXrcsIJJ+T555/P1KlTGy1yS5JtGu1kAAAAAAAAAACArdQ3v/nNVFZW5oQTTkj37t1z6qmnplevXlm9enWee+65TJ06NcOGDdvg/YMHD87o0aMzfPjw9OvXL6+99lruuuuudOvWrda6ww47LDvuuGP233//7LDDDpk1a1ZuueWWDBo0KG3atMnixYvTuXPnHHfccfnWt76V1q1b57HHHsuLL76Ym266aaPf4Sc/+UmmT5+eI488MosWLcrkyZNrfX7KKads8u9TX0I3AAAAAAAAAACAzeCoo47Kq6++mhtuuCH3339/fve736WkpCR77rlnbrrpppx++ukbvPdnP/tZli9fnsrKykyZMiV9+vTJjBkzcvnll9dad8YZZ+Suu+7KzTffnGXLlqVz584577zz8otf/CJJ0qpVq5x99tn5wx/+kN///vdZv359dt111/zHf/xHzjrrrI3O/6c//SlJUlVVlaqqqjqfb8nQrUn1vz7fDjaioqIiw4cPT/PmzRt7FAAAAAAAAAAA4CuiaWMPAAAAAAAAAAAAABsjdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAAA0sq5du2bYsGGNPUZhCd0AAAAAAAAAAAA2k9mzZ+eMM85It27d0rJly7Rt2zb7779/xo4dm08++aSxx9uoZcuW5Yorrsjhhx+er33ta2nSpEkmTZrUKLNs0yinAgAAAAAAAAAAfI7R1zVp7BEy8rLqTb53xowZGTp0aEpKSnLqqaemV69eWb16dZ555plccskl+fOf/5yKiooGnLZhffTRRxk9enR22WWXfOtb38qTTz7ZaLMI3QAAAAAAAAAAABrY22+/nRNPPDFdunTJ448/nk6dOtV8ds455+Rvf/tbZsyY0YgTfr5OnTrlH//4R3bccce89NJL2XvvvRttFq8uBQAAAAAAAAAAaGDXX399li1blokTJ9aK3D6166675vzzz9/g/YsWLcrFF1+c3r17p3Xr1mnbtm2+973v5ZVXXqmzdty4cenZs2datWqV9u3bp7y8PJWVlTWff/zxx7ngggvStWvXlJSUpGPHjjn00EPz8ssvb/Q7lJSUZMcdd6zHt958PNENAAAAAAAAAACggVVVVaVbt27p16/fJt0/Z86c3HfffRk6dGi+8Y1vZMGCBRk/fnwOOuigvPHGGykrK0uSTJgwIeedd16OO+64nH/++Vm5cmVeffXVzJw5MyeffHKS5Mwzz8y0adMyYsSI9OjRIwsXLswzzzyTWbNmpU+fPg32nTcnoRsAAAAAAAAAAEADWrp0aebNm5ejjz56k/fo3bt33nrrrTRt+v9e2vn9738/e+yxRyZOnJhf/vKXSZIZM2akZ8+emTp16gb3mjFjRk4//fTcdNNNNdcuvfTSTZ6tMXh1KQAAAAAAAAAAQANaunRpkqRNmzabvEdJSUlN5LZu3bosXLgwrVu3zu67717rlaPt2rXLe++9lxdffHGDe7Vr1y4zZ87M/PnzN3mexiZ0AwAAAAAAAAAAaEBt27ZNknz88cebvMf69eszZsyY7LbbbikpKcn222+fDh065NVXX82SJUtq1l122WVp3bp1+vbtm9122y3nnHNOnn322Vp7XX/99Xn99dez8847p2/fvhk1alTmzJmzybM1BqEbAAAAAAAAAABAA2rbtm3Kysry+uuvb/IeV199dS666KIceOCBmTx5ch555JE8+uij6dmzZ9avX1+zrnv37vnLX/6Su+++O/3798+9996b/v3754orrqhZc/zxx2fOnDkZN25cysrKcsMNN6Rnz5556KGH/q3vuSUJ3QAAAAAAAAAAABrY4MGDM3v27Dz//PObdP+0adPyne98JxMnTsyJJ56Yww47LN/97nezePHiOmtLS0tzwgkn5Lbbbsu7776bQYMG5aqrrsrKlStr1nTq1Clnn3127rvvvrz99tv5+te/nquuumpTv94WJ3QDAAAAAAAAAABoYJdeemlKS0vzox/9KAsWLKjz+ezZszN27NgN3t+sWbNUV1fXujZ16tTMmzev1rWFCxfW+rtFixbp0aNHqqurs2bNmqxbt67Wq06TpGPHjikrK8uqVavq+7UazTaNPQAAAAAAAAAAAMDW5pvf/GYqKytzwgknpHv37jn11FPTq1evrF69Os8991ymTp2aYcOGbfD+wYMHZ/To0Rk+fHj69euX1157LXfddVe6detWa91hhx2WHXfcMfvvv3922GGHzJo1K7fccksGDRqUNm3aZPHixencuXOOO+64fOtb30rr1q3z2GOP5cUXX8xNN930ud/jlltuyeLFizN//vwkSVVVVd57770kybnnnpvttttu03+kemhS/a/ZH2xERUVFhg8fnubNmzf2KAAAAAAAAAAAbOVGX9eksUfIyMv+vbzqr3/9a2644YY8+uijmT9/fkpKSrLnnnvmxBNPzOmnn56SkpIkSdeuXTNgwIBMmjQpSbJq1ar8/Oc/T2VlZRYvXpw+ffrkxhtvzOWXX54kefLJJ5P8V89z11135c9//nOWLVuWzp07Z8iQIfnFL36Rtm3bZvXq1fnFL36RP/zhD5kzZ07Wr1+fXXfdNWeccUbOOuusz52/a9eueeeddz7zs7fffjtdu3b9t36fL0roRr0I3QAAAAAAAAAAgC2taWMPAAAAAAAAAAAAABsjdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABRak+rq6urGHoIvjyY3rm3sEQAAoEEsmFjV2CMAAAB8pluHDWnsEQAA4Etn5GUSqK2dJ7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAECh1Tt0e+mll1JeXp6qqqrNMQ8AAAAAAAAAAADUsk1jD9CQxo8fn9133z0DBgzYrOcsWrQo48aNy6xZs/LBBx9k5cqV6dixY/r06ZPhw4dn55133qznAwAAAAAAAAAAfJXUO3Tr06dPnn322WyzTfEauQkTJmTw4MGbPXRbunRp3nnnney7777Zcccd07Jly7z77ruZPn16/tf/+l+57bbb0q1bt806AwAAAAAAAAAAwFdFvWu1pk2bpqSkZHPM8qXRtWvX/I//8T/qXD/kkEPygx/8IPfcc08uv/zyRpgMAAAAAAAAAABg69O0vje89NJLKS8vT1VVVZ2/p0+fnuOPPz777bdfBg8enNtvv73O/UceeWR+/OMf580338yZZ56ZAw44IAcffHCuuOKKLFq0qNba8ePHp7y8PPPnz9/gPkkyf/78lJeXJ0keeOCBlJeX1/zzRT3zzDPZe++9M3r06FrXV6xYkSFDhuSwww7LRx99tNE9OnXqlOS/nvhWX6NGjUp5eXmWLVuWa665Joceemj69euX0047La+//nqttevXr8/EiRNz+umnZ+DAgdl3330zaNCgXHPNNVm8eHGttZ/+NuPHj89//ud/5tRTT02/fv0ycODAjB07NmvXrq33rAAAAAAAAAAAAFtSg71/9N57782iRYty1FFHpU2bNnnooYcybty47LDDDjn88MNrrf3ggw9y1lln5eCDD84hhxySN998M9OnT8+sWbNyxx13pGXLlvU6u3379hk9enRGjhyZb3/72znmmGPqPX///v1z0kknpbKyMvvss08GDhyYJLn22mszd+7cjB07Nttvv32te9auXZtly5Zl7dq1mTt3bioqKpIk+++/f73P/9SIESPSvn37/OhHP8qSJUty11135fzzz8/06dNTWlqaJFmzZk3uvPPOHHzwwTnooIPSsmXLvPHGG7n//vvzpz/9KZMnT07z5s1r7fvss89m2rRpOfbYY3PUUUflqaeeyp133pk2bdrktNNO2+R5AQAAAAAAAAAANrcGC93ef//9TJs2La1bt06SHH300Rk8eHCmTJlSJ3R77733ctFFF+Xkk0+uudatW7eMGTMmd999d4YNG1avs7fddtscccQRGTlyZHbaaaccccQRm/Qdzj333Pzxj3/M1VdfnZ49e+aVV17Jgw8+mFNOOSX9+vWrs/7555/PhRdeWPP317/+9VxwwQUZNGjQJp2fJHvssUet155269Ytl19+eR5++OEce+yxSZIWLVrk4YcfrhME7rnnnrnyyivz5JNP5tBDD6312Zw5c3LPPfekrKwsSXLsscfmhBNOyJQpU4RuAAAAAAAAAABAodX71aUbcuSRR9ZEbknSsmXL9O7dO++++26dtaWlpRk6dGita0OHDk1paWmeeOKJhhqp3po3b55rrrkmSXLJJZfkuuuuS48ePTJixIjPXN+7d+/89re/zc0335wRI0bk61//ej7++ON/63Wg/xz/Jal5/ercuXNrrjVp0qQmclu3bl0+/vjjLF68OHvvvXeS1HnVaZIMGDCgJnL7dI/y8vIsXLgwK1as2OR5AQAAAAAAAAAANrcGe6LbTjvtVOfadtttlyVLlnzm2n99tWaLFi2y0047Zd68eQ010ibp3LlzLrzwwlx55ZUpKSnJVVddlW22+eyfqV27dtlnn32SJAceeGAGDRqUE088MYsWLcrPf/7zTTr/X3/Hdu3aJUmd3/HRRx/N5MmT85e//KVOWLd06dLP3Tf5r/8+n+7dqlWrTZoXAAAAAAAAAABgc2uwJ7o1a9asobaq0aRJkw1+tm7dugY/71NPP/10kmTVqlV55513vvB9HTp0SN++fTN9+vSsXr16k87e0O9YXV1d8++PP/54fvrTnyZJLr744owZMya//e1vM27cuDprP9W06Yb/U3/WegAAAAAAAAAAgKJosNCtPubNm5c1a9bUurZ69erMmzev1pPH2rZtm6TuE8pWrVqVjz76aLPMdvfdd+fpp5/OsGHDsssuu2TUqFH1OmvVqlVZt25dli9fvlnmS5IHH3wwJSUlGT9+fI477rgccMAB2WeffdKpU6fNdiYAAAAAAAAAAEBjaZTQbfny5Zk6dWqta1OnTs3y5cszYMCAmmtdunRJksycObPW2srKyqxfv77Ovq1atfrMV6V+UW+99VZ+85vfpLy8PGeffXauvvrqLF++PCNHjqx13sKFCz/z/jlz5uTFF19M586d0759+02e4/N8+nS2f56puro6EydO3GxnAgAAAAAAAAAANJZtGuPQzp07Z8KECZk9e3a6d++eWbNmZfr06enatWtOPPHEmnV9+/ZNly5dMn78+CxZsiRlZWV55ZVX8tprr6Vdu3Z19u3Vq1deeOGFTJo0KTvuuGOaNGmSgQMHfqGZPvnkk/zsZz9LaWlpfvWrX6Vp06bZY489cu655+bmm2/O7bffnuHDhydJJk2alJkzZ2b//fdPWVlZqqurM3v27Dz44INZu3ZtLrvssgb5nTbkkEMOyeOPP54zzzwzgwYNytq1a/PUU09l5cqVm/VcAAAAAAAAAACAxtAooVvHjh1z7bXX5te//nUeeeSRNG/ePIcffnguuOCCbLvttjXrmjVrlptvvjk33nhjpkyZkubNm2ffffdNRUVFfvjDH9bZ9/LLL891112X2267rebVoV80dLv++uvzzjvvZMyYMenQoUPN9ZNOOikvvPBCbr311uy9997p1atX+vfvnwULFuSxxx7LokWLsn79+nTs2DHf/e53c8opp+Sb3/zmv/kLbdzAgQOzYsWKVFZWZuzYsWnTpk0OPPDAjBgxIocccshmPRsAAAAAAAAAAGBLa1JdXV29JQ888sgj06lTp1RUVGzJY2kgTW5c29gjAABAg1gwsaqxRwAAAPhMtw4b0tgjAADAl87Iy7ZoAkUjaNrYAwAAAAAAAAAAAMDGNMqrS7ekJUuWZM2aNRtd07Jly7Ru3brBz16xYkVWrFix0TXNmjVL+/btG/xsAAAAAAAAAACArcVWH7pdcsklefnllze6ZvDgwRk1alSDn33nnXdmwoQJG13TqVOnVFV5ZRIAAAAAAAAAAMCGbPHQbUtHXRdeeGGWLl260TUdOnTYLGcPGjQoe+2110bXlJSUbJazAQAAAAAAAAAAthZb/RPdunfv3mhnd+7cOZ07d2608wEAAAAAAAAAALYGTRt7AAAAAAAAAAAAANgYoRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQmtSXV1d3dhD8OVRUVGR4cOHp3nz5o09CgAAAAAAAAAA8BXhiW4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEJrUl1dXd3YQ/Dl0eTGtY09AgBAo1owsaqxRwAAANhibh02pLFHAAC2IiMvkycAsOk80Q0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAAqt3qHbSy+9lPLy8lRVVW2OeQAAAAAAAAAAAKCWbRp7gIY0fvz47L777hkwYMBmPeeDDz7IjBkz8vzzz+edd97J8uXLU1ZWlv333z8/+MEP0q5du816PgAAAAAAAAAAwFdJvZ/o1qdPnzz77LM54ogjNsc8/5YJEybkySef3OznPP3006moqMh2222X73//+/nJT36SPffcM5WVlfnv//2/56OPPtrsMwAAAAAAAAAAAHxV1PuJbk2bNk1JScnmmOVL49vf/naqqqqy/fbb11w75phj0qtXr1x55ZWZPHlyLrjggsYbEAAAAAAAAAAAYCtS7ye6vfTSSykvL09VVVWdv6dPn57jjz8+++23XwYPHpzbb7+9zv1HHnlkfvzjH+fNN9/MmWeemQMOOCAHH3xwrrjiiixatKjW2vHjx6e8vDzz58/f4D5JMn/+/JSXlydJHnjggZSXl9f880U988wz2XvvvTN69Oha11esWJEhQ4bksMMOq3lS2ze/+c1akdunDj300CTJ7Nmzv/C5nxo1alTKy8uzbNmyXHPNNTn00EPTr1+/nHbaaXn99ddrrV2/fn0mTpyY008/PQMHDsy+++6bQYMG5ZprrsnixYtrrf30txk/fnz+8z//M6eeemr69euXgQMHZuzYsVm7dm29ZwUAAAAAAAAAANiS6v1Etw259957s2jRohx11FFp06ZNHnrooYwbNy477LBDDj/88FprP/jgg5x11lk5+OCDc8ghh+TNN9/M9OnTM2vWrNxxxx1p2bJlvc5u3759Ro8enZEjR+bb3/52jjnmmHrP379//5x00kmprKzMPvvsk4EDByZJrr322sydOzdjx479zLjtX79Xknzta1+r9/mfGjFiRNq3b58f/ehHWbJkSe66666cf/75mT59ekpLS5Mka9asyZ133pmDDz44Bx10UFq2bJk33ngj999/f/70pz9l8uTJad68ea19n3322UybNi3HHntsjjrqqDz11FO5884706ZNm5x22mmbPC8AAAAAAAAAAMDm1mCh2/vvv59p06aldevWSZKjjz46gwcPzpQpU+qEbu+9914uuuiinHzyyTXXunXrljFjxuTuu+/OsGHD6nX2tttumyOOOCIjR47MTjvtlCOOOGKTvsO5556bP/7xj7n66qvTs2fPvPLKK3nwwQdzyimnpF+/fp97//jx45MkgwcP3qTzk2SPPfbI5ZdfXvN3t27dcvnll+fhhx/OsccemyRp0aJFHn744TpB4J577pkrr7wyTz75ZM3T5T41Z86c3HPPPSkrK0uSHHvssTnhhBMyZcoUoRsAAAAAAAAAAFBo9X516YYceeSRNZFbkrRs2TK9e/fOu+++W2dtaWlphg4dWuva0KFDU1pamieeeKKhRqq35s2b55prrkmSXHLJJbnuuuvSo0ePjBgx4nPvnTx5ch577LEcc8wx2XvvvTd5hn+O/5LUvH517ty5NdeaNGlSE7mtW7cuH3/8cRYvXlxz7r++6jRJBgwYUBO5fbpHeXl5Fi5cmBUrVmzyvAAAAAAAAAAAAJtbgz3RbaeddqpzbbvttsuSJUs+c+2/vlqzRYsW2WmnnTJv3ryGGmmTdO7cORdeeGGuvPLKlJSU5Kqrrso222z8Z7rvvvsyduzY9O/fP5dddtm/df6//o7t2rVLkjq/46OPPprJkyfnL3/5S9auXVvrs6VLl37uvsl//ff5dO9WrVr9O2MDAAAAAAAAAABsNg0WujVr1qyhtqrRpEmTDX62bt26Bj/vU08//XSSZNWqVXnnnXey8847b3Dt/fffn6uuuir77rtvrr/++s+N4j7Phn7H6urqmn9//PHH89Of/jQ9e/bMxRdfnB122CEtWrTI+vXrc+6559Za+6mmTTf88L7PWg8AAAAAAAAAAFAUDfbq0vqYN29e1qxZU+va6tWrM2/evFpPHmvbtm2Suk8oW7VqVT766KPNMtvdd9+dp59+OsOGDcsuu+ySUaNGbfCs+++/P1deeWX69u2bG2+8MS1atNgsM/2rBx98MCUlJRk/fnyOO+64HHDAAdlnn33SqVOnLXI+AAAAAAAAAADAltQoodvy5cszderUWtemTp2a5cuXZ8CAATXXunTpkiSZOXNmrbWVlZVZv359nX1btWr1ma9K/aLeeuut/OY3v0l5eXnOPvvsXH311Vm+fHlGjhxZ57yqqqpcddVV2XvvvXPTTTelpKRkk8+tr0+fzvbPM1VXV2fixIlbbAYAAAAAAAAAAIAtpcFeXVofnTt3zoQJEzJ79ux07949s2bNyvTp09O1a9eceOKJNev69u2bLl26ZPz48VmyZEnKysryyiuv5LXXXku7du3q7NurV6+88MILmTRpUnbcccc0adIkAwcO/EIzffLJJ/nZz36W0tLS/OpXv0rTpk2zxx575Nxzz83NN9+c22+/PcOHD0+SPPXUU/nVr36V0tLSHHrooXn88cdr7dWqVatawV5DO+SQQ/L444/nzDPPzKBBg7J27do89dRTWbly5WY7EwAAAAAAAAAAoLE0SujWsWPHXHvttfn1r3+dRx55JM2bN8/hhx+eCy64INtuu23NumbNmuXmm2/OjTfemClTpqR58+bZd999U1FRkR/+8Id19r388stz3XXX5bbbbsvy5cuT5AuHbtdff33eeeedjBkzJh06dKi5ftJJJ+WFF17Irbfemr333ju9evXKm2++mfXr1+fjjz/OVVddVWevTp06bdbQbeDAgVmxYkUqKyszduzYtGnTJgceeGBGjBiRQw45ZLOdCwAAAAAAAAAA0BiaVFdXV2/JA4888sh06tQpFRUVW/JYGkiTG9c29ggAAI1qwcSqxh4BAABgi7l12JDGHgEA2IqMvGyL5gkAbGWaNvYAAAAAAAAAAAAAsDGN8urSLWnJkiVZs2bNRte0bNkyrVu3bvCzV6xYkRUrVmx0TbNmzdK+ffsGPxsAAAAAAAAAAGBrsdWHbpdccklefvnlja4ZPHhwRo0a1eBn33nnnZkwYcJG13Tq1ClVVV5/BQAAAAAAAAAAsCFbPHTb0lHXhRdemKVLl250TYcOHTbL2YMGDcpee+210TUlJSWb5WwAAAAAAAAAAICtxVb/RLfu3bs32tmdO3dO586dG+18AAAAAAAAAACArUHTxh4AAAAAAAAAAAAANkboBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQmlRXV1c39hB8eVRUVGT48OFp3rx5Y48CAAAAAAAAAAB8RXiiGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFFqT6urq6sYegi+PJjeubewRAL6SFkysauwR4Evl1mFDGnsE+FIaeZn/PQQAAAAAAIrJE90AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIVW79DtpZdeSnl5eaqqqjbHPAAAAAAAAAAAAFDLNo09QEMaP358dt999wwYMGCLnPfAAw+ksrIy77zzTkpLS3PAAQdkxIgRad++/RY5HwAAAAAAAAAA4Kug3k9069OnT5599tkcccQRm2Oef8uECRPy5JNPbpGz7rrrrowaNSqtW7fOT37ykwwZMiR/+MMfcsYZZ+STTz7ZIjMAAAAAAAAAAAB8FdT7iW5NmzZNSUnJ5pjlS2Px4sX53e9+lx49euR3v/tdmjVrliTp0aNHLrroovzP//k/c9pppzXylAAAAAAAAAAAAFuHej/R7aWXXkp5eXmqqqrq/D19+vQcf/zx2W+//TJ48ODcfvvtde4/8sgj8+Mf/zhvvvlmzjzzzBxwwAE5+OCDc8UVV2TRokW11o4fPz7l5eWZP3/+BvdJkvnz56e8vDzJf71OtLy8vOafL+qZZ57J3nvvndGjR9e6vmLFigwZMiSHHXZYPvrooyTJk08+mZUrV+aEE06oidyS5MADD8xOO+2Uhx566Auf+6/f5+9//3vOP//8HHjggTnooINy6aWX1pz7qQ8//DBjxozJySefnO985zvp169fhg4dmkmTJmXdunW11lZVVaW8vDwvvvhi7rzzzhx99NHZb7/9MmTIkDzwwAP1nhMAAAAAAAAAAGBLq/cT3Tbk3nvvzaJFi3LUUUelTZs2eeihhzJu3LjssMMOOfzww2ut/eCDD3LWWWfl4IMPziGHHJI333wz06dPz6xZs3LHHXekZcuW9Tq7ffv2GT16dEaOHJlvf/vbOeaYY+o9f//+/XPSSSelsrIy++yzTwYOHJgkufbaazN37tyMHTs222+/fZLkz3/+c5Jkzz33rLNP796988gjj2TFihVp1apVvWb48MMPc8YZZ2TAgAE577zz8te//jW///3vs3z58vz2t7+tWffXv/41TzzxRAYMGJDOnTtn7dq1ef7553PLLbdk3rx5+fnPf15n79/+9rdZtWpVhgwZkhYtWmTatGkZNWpUOnfunL322qtecwIAAAAAAAAAAGxJDRa6vf/++5k2bVpat26dJDn66KMzePDgTJkypU7o9t577+Wiiy7KySefXHOtW7duGTNmTO6+++4MGzasXmdvu+22OeKIIzJy5MjstNNOOeKIIzbpO5x77rn54x//mKuvvjo9e/bMK6+8kgcffDCnnHJK+vXrV7Pu0yesdejQoc4eHTp0SHV1dT788MN06dKlXufPnTs311xzTQ499NCaa02bNs3UqVPz97//PV27dk2S9OnTJ/fff3+aNGlSs+7kk0/OL3/5y9x///0544wzaqK8T61evTp33HFHmjdvniQ55JBDcvTRR+eee+4RugEAAAAAAAAAAIVW71eXbsiRRx5ZE7klScuWLdO7d++8++67ddaWlpZm6NChta4NHTo0paWleeKJJxpqpHpr3rx5rrnmmiTJJZdckuuuuy49evTIiBEjaq1buXJlkqRFixZ19igpKam1pj46dOhQK3JLUvP61blz59Zca9myZU3ktmbNmixZsiSLFy/Ofvvtl/Xr1+eNN96os/fQoUNrIrck6dixY3bZZZda+wIAAAAAAAAAABRRgz3RbaeddqpzbbvttsuSJUs+c+0/R1fJf0VjO+20U+bNm9dQI22Szp0758ILL8yVV16ZkpKSXHXVVdlmm9o/06evVl29enWd16yuWrWq1pr62NBvmKTW77h27dpMmjQpDz74YObOnZvq6upa9yxduvQL7/3+++/Xe04AAAAAAAAAAIAtqcFCt2bNmjXUVjX++dWc/2rdunUNft6nnn766ST/Fa2988472XnnnWt9/ulrQT/88MM6n3344Ydp0qTJZ77W9PM0bbrhB+z9c8w2ZsyYTJkyJYceemhOO+20tG/fPttss03efPPNjBs3rk74trG9P2stAAAAAAAAAABAkTTYq0vrY968eVmzZk2ta6tXr868efNqPXmsbdu2Seo+oWzVqlX56KOPNstsd999d55++ukMGzYsu+yyS0aNGlXnrJ49eyZJXn311Tr3v/baa+nSpUtatWq1WeZLkgcffDB9+vTJNddck8GDB2f//ffPPvvsk9LS0s12JgAAAAAAAAAAQGNplNBt+fLlmTp1aq1rU6dOzfLlyzNgwICaa126dEmSzJw5s9baysrKrF+/vs6+rVq1+sxXpX5Rb731Vn7zm9+kvLw8Z599dq6++uosX748I0eOrHXeQQcdlJKSktxzzz21niz39NNPZ968eTn88MM3eYYvomnTpnWexPbJJ5+ksrJys54LAAAAAAAAAADQGBrs1aX10blz50yYMCGzZ89O9+7dM2vWrEyfPj1du3bNiSeeWLOub9++6dKlS8aPH58lS5akrKwsr7zySl577bW0a9euzr69evXKCy+8kEmTJmXHHXdMkyZNMnDgwC800yeffJKf/exnKS0tza9+9as0bdo0e+yxR84999zcfPPNuf322zN8+PAkSfv27XPWWWfl17/+dc4+++wMHDgwH374YSZPnpyuXbvm5JNPbpDfaUMOOeSQ/P73v89Pf/rT9O3bNwsXLkxVVVW22267zXouAAAAAAAAAABAY2iU0K1jx4659tpr8+tf/zqPPPJImjdvnsMPPzwXXHBBtt1225p1zZo1y80335wbb7wxU6ZMSfPmzbPvvvumoqIiP/zhD+vse/nll+e6667LbbfdluXLlyfJFw7drr/++rzzzjsZM2ZMOnToUHP9pJNOygsvvJBbb701e++9d3r16pUkOeWUU7LddtulsrIyN954Y0pLS/Pd734355577mZ9bWmSXHTRRSktLc2jjz6ap556KjvssEOOOeaY9OjRI2efffZmPRsAAAAAAAAAAGBLa1L9r+/A3MyOPPLIdOrUKRUVFVvyWBpIkxvXNvYIAF9JCyZWNfYI8KVy67AhjT0CfCmNvGyL/u8hAAAAAADAF9a0sQcAAAAAAAAAAACAjWmUV5duSUuWLMmaNWs2uqZly5Zp3br1VnU2AAAAAAAAAADA1mKrD90uueSSvPzyyxtdM3jw4IwaNWqrOhsAAAAAAAAAAGBrscVDt6qqqi163oUXXpilS5dudE2HDh22urMBAAAAAAAAAAC2Flv9E926d+/+lTwbAAAAAAAAAABga9G0sQcAAAAAAAAAAACAjRG6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACF1qS6urq6sYfgy6OioiLDhw9P8+bNG3sUAAAAAAAAAADgK8IT3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhdakurq6urGH4MujyY1rG3sEgK+EBROrGnsE/sWtw4Y09gjAVmbkZf5XDAAAAAAA4IvyRDcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACg0oRsAAAAAAAAAAACFJnQDAAAAAAAAAACg0IRuAAAAAAAAAAAAFJrQDQAAAAAAAAAAgEITugEAAAAAAAAAAFBoQjcAAAAAAAAAAAAKTegGAAAAAAAAAABAoQndAAAAAAAAAAAAKDShGwAAAAAAAAAAAIUmdAMAAAAAAAAAAKDQhG4AAAAAAAAAAAAUmtANAAAAAAAAAACAQhO6AQAAAAAAAAAAUGhCNwAAAAAAAAAAAApN6AYAAAAAAAAAAEChCd0AAAAAAAAAAAAoNKEbAAAAAAAAAAAAhSZ0AwAAAAAAAAAAoNCEbgAAAAAAAAAAABSa0A0AAAAAAAAAAIBCE7oBAAAAAAAAAABQaEI3AAAAAAAAAAAACk3oBgAAAAAAAAAAQKEJ3QAAAAAAAAAAACi0eoduL730UsrLy1NVVbU55gEAAAAAAAAAAIBatmnsARrS+PHjs/vuu2fAgAGb/ax77703f/zjHzNr1qzMnTs369evz0svvbTZzwUAAAAAAAAAAPiqqXfo1qdPnzz77LPZZpviNXITJkzI4MGDt0joNmnSpCxZsiS77757Vq5cmQULFmz2MwEAAAAAAAAAAL6K6l2rNW3aNCUlJZtjli+V8ePHZ8cdd0zTpk1zwQUXCN0AAAAAAAAAAAA2k6b1veGll15KeXl5qqqq6vw9ffr0HH/8/9/efYdZUZ2PA3+XsixlAYElgAiogCJFURCsCCpiAXtHwUYUDcEWS4wi9oIEuwhSBH/BgiH2EjFGExuKLRILYiEoRelI2/n94bP3y2V3YXdd2Ct+Ps/DI/fMmTPvzJw5O959Oee42GOPPeKwww6LcePGFdq/d+/eMWDAgJgxY0acffbZsc8++0SPHj3iqquuiu+//z6t7n333RedOnWK//3vf8W2ExHxv//9Lzp16hQREU8++WR06tQp9aekXn311ejcuXMMHTo0rXz58uVx1FFHRc+ePWP+/Pmp8iZNmkSlSqW+fMUaMGBA9O7dO+bNmxeXX355dO/ePfbaa68477zz4ssvv0yru2zZsrj77rujX79+sf/++8cee+wRRxxxRNxxxx3x448/ptUt7f0BAAAAAAAAAADINOW2/uhjjz0W33//ffTp0ydyc3PjmWeeiTvuuCN+85vfRK9evdLqzp07N84555zo0aNH7L///jFjxoz429/+Fh9//HGMHz8+cnJySnXsrbbaKoYOHRpXXnlldOzYMY488shSx7/33nvHiSeeGA899FB06dIlDjrooIiIuPHGG+Prr7+OESNGRIMGDUrdbmmsWLEizjrrrGjfvn2ce+65MXv27PjLX/4SF154YUyaNCkqV64cERHz5s2LKVOmRI8ePaJXr15RuXLleOedd2L8+PHx3//+N+68885CbZfm/gAAAAAAAAAAAGSSckt0+/bbb+PRRx+NWrVqRUTE4YcfHocddlhMmjSpUCLVN998ExdccEGcdNJJqbLtttsuhg8fHn/5y1+if//+pTp29erV45BDDokrr7wytt566zjkkEPKdA6/+93v4t13343rr78+2rZtG++99148/fTT0bdv39hzzz3L1GZpLFy4ME455ZTo169fqmyrrbaK22+/Pd58883YY489IiJi6623jqeeeiqqVPm/23fcccfFPffcE6NHj44PP/ww2rVrl9Z2ae4PAAAAAAAAAABAJim3tTd79+6dSqKKiMjJyYn27dvHV199VahuzZo149hjj00rO/bYY6NmzZoxderU8gqp1KpWrRo33HBDRERcfPHFcdNNN8VOO+0U55133mY5fqVKleKEE05IK+vcuXNERNp1rFq1airJbc2aNbF48eJYuHBh7L777hER8eGHHxZquzT3BwAAAAAAAAAAIJOU24xuW2+9daGyOnXqxKJFi4qsW7Vq1bSy7Ozs2HrrrWP27NnlFVKZNG3aNM4///y49tpro1q1anHdddelzZy2KeXl5UW1atXSyurUqRMRUeg6PvLII/HYY4/FzJkzIz8/P23bkiVLCrVdmvsDAAAAAAAAAACQScotg6ty5crl1VRKVlZWsdvWrl1b7scr8Morr0RExMqVK+PLL7+MbbbZZpMda12VKhU/wV6SJKm/T5gwIf785z9H165d44QTTogGDRpE1apVY968eTFkyJBCiW8Rm+b+AAAAAAAAAAAAbA7ltnRpacyePTtWr16dVrZq1aqYPXt22sxjtWvXjoiIxYsXp9VduXJlzJ8/f5PE9pe//CVeeeWV6N+/fzRr1iyGDBmyyY5VVk8//XQ0adIkbr/99jjiiCNi7733ji5dukS9evUqOjQAAAAAAAAAAIByVyGJbsuWLYtHHnkkreyRRx6JZcuWxX777Zcqa968eUREvPHGG2l1H3rooSJnLatRo8bPWorzk08+idtvvz06deoUAwcOjOuvvz6WLVsWV155ZZHHqyiVK1eOrKystFne1qxZE2PHjq24oAAAAAAAAAAAADaRclu6tDSaNm0a999/f3z++efRpk2b+Pjjj+Nvf/tbtGjRIk444YRUvd133z2aN28e9913XyxatCiaNGkS7733XnzwwQdRt27dQu22a9cu3nzzzRg7dmw0atQosrKy4qCDDipRTCtWrIjLL788atasGddcc01UqlQpdtxxx/jd734Xt912W4wbNy5OO+20VP1XXnklPvnkk4iI+PrrryMiYtSoURERkZubG8cff3xZL89G7b///nHnnXfGoEGDonv37rFs2bJ47rnnokqVCrmdAAAAAAAAAAAAm1SFZEY1bNgwbrzxxvjzn/8czz33XFStWjV69eoVgwcPjurVq6fqVa5cOW677ba49dZbY9KkSVG1atXo2rVrjBw5Ms4444xC7V566aVx0003xZgxY2LZsmURESVOdLv55pvjyy+/jOHDh0deXl6q/MQTT4w333wz7r333ujcuXO0a9cuIiJeeumlePLJJ9PauPfeeyMionHjxps00e2UU06JJEliypQpMWzYsKhfv34ceOCB0adPnzj22GM32XEBAAAAAAAAAAAqQlay7vqXm0Hv3r2jcePGMXLkyM15WMpJ1q1rKjoEgF+F70Y/UdEhsJ57+x9V0SEAW5grL9ms/ysGAAAAAADwi1apogMAAAAAAAAAAACADamQpUs3p0WLFsXq1as3WCcnJydq1apV7sdeunRp/PjjjxusU7Vq1ahTp065HxsAAAAAAAAAAGBLscUnul188cXxzjvvbLDOYYcdFkOGDCn3Y996663x5JNPbrDOrrvuahlXAAAAAAAAAACADdjsiW5PPPHEZj3e+eefH4sXL95gnby8vE1y7FNPPTUOPvjgDdapXbv2Jjk2AAAAAAAAAADAlmKLn9GtTZs2FXbs7bbbLrbbbrsKOz4AAAAAAAAAAMCWoFJFBwAAAAAAAAAAAAAbItENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMJtENAAAAAAAAAACAjCbRDQAAAAAAAAAAgIwm0Q0AAAAAAAAAAICMlpUkSVLRQfDLMXLkyDjttNOiatWqFR0KAAAAAAAAAADwK2FGNwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAymkQ3AAAAAAAAAAAAMppENwAAAAAAAAAAADKaRDcAAAAAAAAAAAAyWpWKDoBfjiRJYsWKFbF48eKoWrVqRYcDAAAAAAAAAABsAXJzcyMrK2uDdbKSJEk2Uzz8ws2fPz/y8vIqOgwAAAAAAAAAAGALsmjRoqhdu/YG65jRjRKrVq1a7LLLLvHUU09FrVq1Kjoc4Fdo6dKlceihhxqHgApjHAIqmnEIqGjGIaCiGYeAimYcAiqacQioaJtqHMrNzd1oHYlulFhWVlZUrlw5ateu7QcmUCEqVapkHAIqlHEIqGjGIaCiGYeAimYcAiqacQioaMYhoKJV5DhUabMeDQAAAAAAAAAAAEpJohsAAAAAAAAAAAAZTaIbJZadnR1nnXVWZGdnV3QowK+UcQioaMYhoKIZh4CKZhwCKppxCKhoxiGgohmHgIpWkeNQVpIkyWY/KgAAAAAAAAAAAJSQGd0AAAAAAAAAAADIaBLdAAAAAAAAAAAAyGhVKjoAMsOsWbPi5ptvjvfffz9q1qwZhxxySAwcODCqVq26wf2SJIlx48bFI488EgsXLozWrVvHBRdcEO3bt99MkQNbirKOQ7179445c+YUKn/ttdeiWrVqmypcYAv09ddfx4MPPhgffvhhfP7559G8efN4+OGHN7qf9yGgvJR1HPI+BJSHF198MZ5++umYMWNGLF68OJo1axbHH3989OnTJ7Kysordz7sQUF7KOg55FwLKy6uvvhrjx4+PmTNnxrJly6Jhw4bRrVu3GDBgQNSqVWuD+/71r3+N8ePHx7fffhvNmzePgQMHxj777LOZIge2FGUdhwYMGBDvvPNOofJHH300WrRosQkjBrZky5cvj2OOOSbmzp0b48ePj5122qnYupvz+yGJbsTixYvj7LPPjmbNmsUtt9wSc+fOjeHDh8ePP/4Yl1xyyQb3HTduXNx3331x3nnnRatWreKRRx6J8847LyZOnBhNmzbdTGcA/NL9nHEoImL//fePvn37ppVlZ2dvqnCBLdTnn38er732WrRt2zby8/MjPz+/RPt5HwLKS1nHoQjvQ8DPN3HixGjcuHEMHjw4ttpqq3jjjTfiuuuui++++y4GDBhQ7H7ehYDyUtZxKMK7EFA+Fi9eHG3bto3jjz8+6tSpE59//nmMHDkyPv/887jrrruK3e+5556L6667Lk4//fTo3LlzPP/883HRRRfFqFGjJP8DpVLWcSgiYuedd47BgwenlTVu3HgTRgts6UaNGhVr164tUd3N+f2QRDfisccei2XLlsUtt9wSderUiYiItWvXxk033RSnn3565OXlFbnfypUrY8yYMdG3b984+eSTIyKiY8eOcdRRR8WECRPi0ksv3WznAPyylXUcKlCvXj1fGAA/27777hv77bdfREQMGTIk/vOf/2x0H+9DQHkqyzhUwPsQ8HMNHz486tatm/rcuXPnWLRoUUycODHOPPPMqFSpUqF9vAsB5aks41AB70JAeTjkkEPSPnfq1Cmys7Pjuuuui3nz5hX7PfV9990XPXv2jHPOOSe132effRb3339/3H777Zs8bmDLUdZxKCIiNzfX+xBQbmbNmhWPPPJIDB48OG644YYN1t3c3w8V/3+G/Gr861//it133z2VXBIRceCBB0Z+fn68/vrrxe73/vvvx7Jly+KAAw5IlVWtWjW6d+8er7322iaNGdiylHUcAihPG/qlSXG8DwHlqSzjEEB5WTe5pMAOO+wQy5YtixUrVhS5j3choDyVZRwC2NQKvrNevXp1kdu/+eab+Oqrr+LAAw9MK+/Zs2e89dZbsWrVqk0eI7Bl29g4BLAp3HzzzXH00UdH8+bNN1p3c38/5Ft0YtasWYXW5s7NzY0GDRrErFmzNrhfRBTad9ttt41vv/02fvzxx/INFNhilXUcKvDss8/GHnvsEfvss08MGjQoPvvss00TKMB6vA8BmcL7ELApTJ8+PRo2bBg1a9Yscrt3IWBT29g4VMC7EFCe1q5dGytXrowZM2bEqFGjYt99940mTZoUWbe496EWLVrE6tWr43//+98mjhbYEpVmHCrwzjvvxN577x177rlnDBgwIN55553NFC2wpXnxxRfj888/jzPPPLNE9Tf390OWLiUWL14cubm5hcpzc3Nj8eLFG9wvOzs7qlWrVmi/JEliyZIlkZOTU+7xAlueso5DET8t8dWuXbto1KhRzJ49Ox544IE444wzNsl63wDr8z4EZALvQ8CmMH369Hj++edj8ODBxdbxLgRsSiUZhyK8CwHlr3fv3jF37tyIiNhzzz3juuuuK7bukiVLIiKiVq1aaeW1a9eOiIhFixZtoiiBLVlpxqGIiN122y0OPfTQaNasWcybNy8mTJgQAwcOjJEjR0aHDh02R8jAFuLHH3+M4cOHx8CBAwu93xRnc38/JNENgF+0iy++OPX3jh07RteuXePoo4/eJOt9AwBkIu9DQHn77rvv4rLLLotOnTrFCSecUNHhAL9CpRmHvAsB5W3EiBGxYsWKmDlzZowePTrOP//8uOuuu6Jy5coVHRrwK1Hacei3v/1t2ud99tknjjvuuBg1alTcfvvtmyNkYAsxevToqF+/fvTp06eiQymWRDeidu3asXTp0kLlS5YsSf2Lk+L2W7VqVaxcuTItM3PJkiWRlZVV5OxMAEUp6zhUlAYNGsQuu+wSH3/8cXmFB1As70NAJvI+BPwcS5YsiUGDBkWdOnXi5ptvjkqVKhVb17sQsCmUZhwqinch4Odq1apVRER06NAhdtpppzjppJNi6tSpccABBxSqW/C+s3Tp0mjQoEGqvGClkjp16myGiIEtTWnGoaJUr1499t577/j73/++KcMEtjBz5syJCRMmxC233JL63f2KFSsiImL58uWxfPnyqFGjRqH9Nvf3QxLdiBYtWqTWzC2wdOnSmD9/fqE1dNffLyLiyy+/jNatW6fKZ82aFY0aNbI0BVBiZR2HACqa9yEAYEvy448/xuDBg2Pp0qUxZsyYjS5R4V0IKG+lHYcANrVWrVpFlSpV4ptvvilye8H70KxZs9K+y541a1ZUrVo1tt56680QJbAl29g4BFBeZs+eHatXr47BgwcX2nb22WdHu3btYuzYsYW2be7vh0r3T6HYIu25557x5ptvxpIlS1JlL774YlSqVCm6du1a7H4dOnSImjVrxosvvpgqW7NmTUydOjX22muvTRozsGUp6zhUlHnz5sX06dNjp512Ku8wAQrxPgRkIu9DQFmsWbMmLrvsspg1a1bccccd0bBhw43u410IKE9lGYeK4l0IKE8ffvhhrFmzptiEtaZNm0azZs0KzZr0wgsvROfOnaNq1aqbI0xgC7axcagoK1asiH/+85/eh4BS2WGHHeLee+9N+3PBBRdERMRll10Wl156aZH7be7vh8zoRhx99NExadKkuPDCC+P000+PuXPnxogRI+Koo46KvLy8VL1zzjkn5syZE3/9618jIqJatWpx2mmnxciRI2OrrbaKli1bxiOPPBKLFi2Kvn37VtDZAL9EZR2Hnn322Xj11Vdjr732iry8vPjmm29i7NixUblyZeMQUGo//vhjvPrqqxHx0/TMy5YtS72U77bbbrHVVlt5HwI2qbKMQ96HgPJy0003xT//+c8YPHhwLFu2LD744IPUth122CGys7O9CwGbVFnGIe9CQHm6+OKLo02bNtGqVauoVq1afPLJJ/Hggw9Gq1atYr/99ouIiKFDh8ZTTz0Vb7zxRmq/AQMGxJ/+9Kdo2rRp7LbbbvHCCy/Ehx9+GPfff38FnQnwS1WWcejdd9+N8ePHR/fu3aNJkyYxb968mDBhQixYsCBuvPHGCjwb4JcmNzc3OnXqVOS2Nm3axI477hgRFZ87JNGNqF27dtxzzz1xyy23xIUXXhg1a9aMI444IgYOHJhWb+3atbF27dq0sn79+kWSJDFhwoT44YcfonXr1nHHHXdE06ZNN+cpAL9wZR2Htt5665g3b14MGzYslixZErm5udG5c+f47W9/a0p4oNS+//77Qv8apeDzvffeG506dfI+BGxSZRmHvA8B5eX111+PiIg///nPhbb97W9/iyZNmngXAjapsoxD3oWA8tS2bdt4/vnnY9y4cZGfnx+NGzeOI488Mvr27ZuamS0/P7/Q+1CvXr3ixx9/jHHjxsXYsWOjefPmceutt0aHDh0q4jSAX7CyjEMNGjSINWvWxF133RWLFi2K6tWrR4cOHeKyyy6Ldu3aVdSpAFuwiv5+KCtJkqTcWwUAAAAAAAAAAIByUqmiAwAAAAAAAAAAAIANkegGAAAAAAAAAABARpPoBgAAAAAAAAAAQEaT6AYAAAAAAAAAAEBGk+gGAAAAAAAAAABARpPoBgAAAAAAAAAAQEaT6AYAAAAAAAAAAEBGk+gGAAAAAAAAAABARpPoBgAAAFS4uXPnRp06deL+++9PK+/fv3+0aNGiYoLaQgwZMiSysrJi1qxZm+V4Y8eOLXS8FStWRJMmTeLqq68udXvF9Q3KruAevfzyyxUdChXs544P+tKv16xZsyIrKyuGDBmyWY/78ssvR1ZWVowdO7ZM+0+fPj0qVaoU//jHP8o3MAAAADYLiW4AAABAhbviiisiLy8vTjvttBLV//bbb+Oiiy6Kdu3aRW5ubtSuXTtatWoVJ5xwQkyePDmt7n777Re1atUqtq2CRI+33367yO0//PBDVK9ePbKysuLBBx8stp0WLVpEVlZW6k92dna0aNEizjzzzPj6669LdF5bqurVq8ell14at9xyS8yZM6dU+5a2b/DrNn369BgyZMhmS+yk4s2aNSuGDBkS06dP36zH1dcKW7hwYQwZMiSjEx932WWXOOKII+LCCy+MJEkqOhwAAABKSaIbAAAAUKG++eabeOCBB+J3v/tdVKlSZaP1v/zyy9h5553jrrvuiq5du8aNN94YN9xwQxx22GExY8aMGDNmTLnGN3HixFi5cmVsu+228cADD2ywbtOmTePBBx+MBx98MEaMGBFdunSJBx54ILp06RLz588v17h+ac4444zIysqK2267rcT7lLZvUDKnnHJKrFixIvbdd9+KDqXcTZ8+Pa6++mrJR78is2bNiquvvrpCEt1+zX2tefPmsWLFirjiiitSZQsXLoyrr746oxPdIiIGDx4c06ZNi6effrqiQwEAAKCUfEMIAAAAVKj77rsvsrKy4sQTTyxR/VtvvTXmzp0bf/3rX+Pwww8vtP3bb78t1/hGjx4d3bt3j8MPPzwGDx4cM2fOjO22267IunXq1Im+ffumPp9zzjnRsGHDuPPOO2PMmDFx8cUXl2tsvyQ1a9aMo446KsaOHRvXXnttVKtWbaP7lLZvVLS1a9fGypUro0aNGhUdygZVrlw5KleuXNFhAL9gWVlZkZOTU9FhlMk+++wTLVq0iHvvvTcOPfTQig4HAACAUjCjGwAAAPzCjB07NrKysuLvf/97DB06NJo3bx7Vq1ePLl26xOuvvx4REf/4xz9i7733jpo1a0bjxo3jmmuuKbKtt99+O4488sho0KBBVKtWLXbYYYe47rrrYs2aNWn13nzzzejfv3+0bt06atSoEbm5ubHXXnvF448/XqjN/v37R1ZWVixatCiV6JWTkxN77bVXvPHGG4XqP/LII9GpU6do2LBhic7/008/jYiI/fffv8jtjRo1KlE7JfHOO+/E9OnTo1+/fnHSSSdFlSpVNjqr2/oOOuigiIj47LPPiq3zzDPPRFZWVtx+++1Fbt9jjz0iLy8vVq9eHRGlux9FKbhHRcnKyor+/fsXKp80aVLsvffekZubGzVq1IguXbrEo48+WqLjFTj44INj/vz5MXXq1BLVL65v5Ofnx3XXXRf77rtvNGrUKLKzs6NZs2ZxzjnnxIIFC1L1Fi5cGDk5OXHUUUcV2f5ll10WWVlZaTNBLVq0KC655JJo2bJlVKtWLfLy8uLEE0+MmTNnpu1b8By++OKLcc0118T2228fOTk58fDDD0dExPPPPx/HH398bLfddlG9evWoW7du9OzZM/7xj38UGctjjz0WO++8c+Tk5ESzZs3i6quvjhdffDGysrJi7NixaXVXrlwZ119/fbRt2zZycnKibt260bt373j33XdLdF0LYl931qXyGldatGgR++23X7zzzjvRo0ePqFWrVtSrVy/69esXc+fOTau7ZMmSuOKKK6JLly6pMahly5Zx6aWXxvLlywu1nSRJ3H///dGlS5eoVatW1KpVK9q3bx9XXnllRPy0DHHBErfdu3dPLSNcVH9e3/vvvx9HHnlk1K9fP3JycmKnnXaKm2++OdauXZtWr7TjW1EKlkv+z3/+E4MHD47GjRtHjRo1Yv/994///ve/ERExefLk2HXXXaN69erRokWLGDlyZJFtjRo1KlWvTp060bNnz3j11VcL1cvPz48bbrghtt1228jJyYl27drFxIkTi41xzpw5cc4550SzZs0iOzs7mjRpEgMGDCh0D0urpNd5v/32ixYtWhTaf9asWZGVlRVDhgyJiJ/6bffu3SMi4rTTTkvd8/322y8iIl5++eXUM3THHXdE69atIycnJ1q3bh133HFHofYL+u/61m0noux9raD/LFiwIPr37x8NGjSI3NzcOOKII1JJ2iNHjow2bdpETk5O7LjjjjFlypRC7dx9993Rs2fP2HrrrSM7OzsaN24cffv2LXJ2ubVr18Y111wTzZs3j5ycnOjQoUNMmjQp1Q/X3ac0/Xv9e/Hyyy/HtttuGxERV199deqaFNzH9a9hUddlfVOmTImOHTtGTk5ObLPNNvGnP/0p9XNwfaUZF7OysuKggw6KZ599NpYuXVpkewAAAGQmM7oBAADAL9Sll14aa9eujd///vexatWqGDZsWPTs2TPGjx8fZ5xxRgwYMCBOPvnkePjhh+PKK6+MbbfdNm22saeeeiqOOuqoaNmyZVx44YVRr169+Pe//x1XXnllTJ8+PR555JFU3ccffzxmzJgRxx13XDRv3jwWLFgQ48aNi6OOOiomTpwYJ510UqH4DjrooMjLy4srr7wyFixYELfddlsceuih8cUXX0Rubm5ERHz33Xfx3//+NwYNGlTi895+++0jIuL++++PwYMHF5uwtb7ilg4tKqGmwOjRo6NWrVpx9NFHR82aNeOwww6LcePGxdChQ6NSpZL9+8GCxLwGDRoUW6dnz57RqFGjGD9+fKFr8emnn8brr78egwYNiqpVq0ZE2e7Hz3HFFVfEddddF7169YprrrkmKlWqFI8//ngce+yxceedd8a5555bonb22GOPiPgp4aFXr14brLuhvrFq1aq45ZZb4uijj47DDz88atasGW+99VaMHj06Xn311Zg2bVpkZ2dH3bp1o0+fPjFlypT4/vvvo169eqk28vPzY+LEidGhQ4fYZZddIuKnJLc999wzvvrqqzj99NOjbdu2MWfOnLj77rujS5cu8fbbb0fz5s3TYrnoooti9erVcdZZZ0Xt2rVjhx12iIifEnC+//77OPXUU6Np06Yxe/bsGDVqVOy///4xderU2GeffVJtTJo0KU488cTYfvvt46qrrooqVarEuHHj4oknnih07qtXr45evXrFv/71rzjllFPivPPOi0WLFsX9998fe+21V7zyyivRqVOnEt2PovzccSXipyVn999//zj66KPjmGOOiXfeeSceeOCBePvtt+Ott95KzXhXcE2OPvroVCLpP/7xj7j55pvj3Xffjeeeey6t3VNOOSUmTpwYXbp0iT/+8Y9Rt27dmDFjRjz66KMxdOjQOOqoo2LOnDkxcuTIuPzyy6NNmzYR8X9jRnHefvvt6NatW1StWjXOPffcaNSoUTzxxBNxySWXxHvvvVdkQlhJxreN6devX9SqVSsuv/zymDdvXgwbNiwOOuiguOaaa+IPf/hDnHPOOXH66afH6NGj47e//W3stNNOsffee6f2v+SSS+Lmm2+O3XffPa6//vpYsmRJjBw5Mrp37x5TpkyJQw45JFX3ggsuiBEjRsS+++4b559/fsydOzfOPffcImen/Oqrr2KPPfaIVatWxRlnnBHbb799fPbZZ3HPPffE1KlT4+233446deqU6Bx/7nXemH333Tcuv/zyuP7662PAgAGp5+o3v/lNWr077rgjvv322/jtb38bubm58f/+3/+LQYMGxffffx9XXXVVqY9b1r5WoFevXtG0adMYOnRofPbZZ3H77bfHkUceGUcddVSMHDkyzjjjjMjJyYnbb789jjnmmPjkk09SSWQRP81s2rVr1xg0aFDUq1cvPvzwwxg1alS89NJL8cEHH0T9+vVTdc8777y49957o3v37nHRRRfFvHnzYuDAgWntra8s/btNmzYxfPjwOP/881PnEhFRq1atEl2T9T3++ONx9NFHR4sWLeLKK6+MKlWqxJgxY+Kpp54qVLcs4+Iee+wR9913X7z66qsb/XkEAABABkkAAACAX5QxY8YkEZF07NgxWblyZap8ypQpSUQkVapUSd56661U+cqVK5NGjRolXbt2TZWtWLEi+c1vfpPss88+yerVq9Pav+2225KISKZOnZoqW7p0aaE4li1blrRu3Tpp06ZNWnm/fv2SiEjOOeectPKHH344iYjk3nvvTZW99NJLSUQkI0aMKPJc+/XrlzRv3jyt7PPPP09q166dRESyzTbbJCeddFIyfPjw5O233y6yjW7duiURsdE/616zgmtUt27dpF+/fqmyv/71r0lEJE8//XSh4zRv3jzZcccdk3nz5iXz5s1LZs6cmTzwwANJnTp1kipVqiQffPBBkfEVuOiii5KISD766KO08iuuuCKJiGTatGmpstLcj6uuuiqJiOSLL75IlRXco6JERNo5T5s2LYmI5LLLLitU9/DDD09yc3OTxYsXp8oK+ue6x1tXlSpVksMOO6zIbevaUN/Iz89Pli9fXqh81KhRSUQkkyZNSpU9+eSTSUQkd911V1rdF198MYmIZNiwYamyQYMGJTk5Ocn06dPT6s6aNSvJzc1Nuy4F59m6detk2bJlhWIp6h59++23Sf369ZODDz44VbZ69eqkSZMmScOGDZPvv/8+Vb5kyZJk2223TSIiGTNmTKq84Pl89tln09petGhRss022yTdunUrdNz1FcS+7jNeHuNKkvz0HEREMnz48LTygrhvuOGGtDZWrVpVKL6CPv/GG2+kyiZNmpRERNK3b99k7dq1afXX/VzUuW3MnnvumVSuXDl57733UmX5+fnJsccem0RE8uKLL6bKSzO+FafgmTzssMOS/Pz8VPmIESOSiEhyc3OTr776KlU+d+7cpFq1askJJ5yQKpsxY0aSlZWV7LXXXmn3a/bs2UmdOnWS5s2bJ2vWrEmr26NHj1RZkvz0bGdlZRV6Xvv06ZPk5eUlX3/9dVrcb731VlK5cuXkqquuSpWV5nqX5jp369at0NifJEnyxRdfJBGRFsPUqVMLPSfrb6tVq1ba+axcuTLp3LlzUqVKlbTy5s2bF/kMFXWMsvS1gv4zcODAtPLzzz8/9TNt0aJFqfL33nsviYjk0ksvTatf1PhSMKbddNNNqbIPP/wwiYjkoIMOSntO3n///aRSpUrF/mwoSf8u6l4UVVZgQ/dp/Z9Ja9asSbbZZpukfv36ybx581LlCxcuTJo1a1Yu4+I///nPJCKSW2+9tdA2AAAAMpelSwEAAOAX6pxzzons7OzU54KZbLp06ZI2c0l2dnbsvvvuqZnFIiJeeOGF+O677+K0006LhQsXxvz581N/CmYBev7551P1a9asmfr78uXLY8GCBbF8+fLo0aNHfPzxx7F48eJC8Z1//vlpn3v06BERkRbHvHnzIiLSZtramO222y7ee++91CxiDz30UJx//vnRqVOn6NChQ0ybNq3QPjk5OfHCCy8U+eeUU04p8jiTJ0+OhQsXRr9+/VJlhxxySOTl5RW7fOmMGTMiLy8v8vLyYrvttovTTz89GjRoEFOmTIl27dpt8LwKjjN+/PhUWZIkMWHChGjXrl3suuuuqfKy3I+ymjhxYmRlZUW/fv3S+sn8+fOjT58+sWTJkvj3v/9d4vbq1atXouUPN9Q3srKyonr16hHx07J8BX24oI+tu8TeQQcdFL/5zW/SrmvET9e5SpUqcfLJJ0fET9d64sSJse+++8bWW2+ddp41a9aMrl27pj0TBc4555zUDGXrWvceLV26NBYsWBCVK1eOLl26pMU3bdq0+N///hf9+/ePrbbaKlVeq1atOPvsswu1O2HChNhxxx1jt912S4tx1apVceCBB8arr74aK1asKOKKlszPGVcK1K5dOwYOHJhWNnDgwKhdu3ba8rrZ2dmpWQrXrFkTP/zwQ8yfPz8OOOCAiEi/jwWzfd16662FZlMs6eyKRZk7d27861//ij59+kSHDh1S5VlZWfHHP/4xIqLIJYFLMr5tzKBBg9JmpCy41n369IltttkmVZ6Xlxc77LBDWttTpkyJJEniD3/4Q9r9atKkSZx22mnx5ZdfppZsLKh7wQUXROXKlVN1d9111zjwwAPTYlq0aFE8+eST0adPn8jJyUnrYy1atIiWLVsW+RxsTFmvc3k5+eSTo2nTpqnP2dnZcf7558eaNWuKnDlxUxs8eHDa54J7f+qpp0bt2rVT5R06dIjatWsX6lcF40t+fn4sWrQo5s+fHzvvvHPUqVMn7bl58sknIyLi97//fdpz0r59+9Sy2kUpj/79c0ybNi2+/vrrOO2009JmQ61Tp065jYsFs9793OV4AQAA2LwsXQoAAAC/UOsvOVeQJFPUcmRbbbVVLFiwIPX5448/joiI008/vdj2v/vuu9Tf586dG1dccUVMmTKlyF8KL1y4MO2X80XFV/BL5XXjKEjySJKk2DiK0qJFi7jzzjvjzjvvjDlz5sSrr74aDz74YDzxxBNx2GGHxUcffZSWIFW5cuVU8sz6Xn311SLLR48eHXl5edG0adP47LPPUuU9e/aMRx55JObPn19oOdIWLVrE/fffHxE/JVI0adIkWrZsWaJzKkhmmzhxYlx//fVRqVKleOWVV2LWrFlx8803p9Uty/0oq48//jiSJIkdd9yx2Drr9pWNSZKkRMvNbqxvPPzwwzFs2LB49913Y/Xq1Wnbfvjhh9TfC5LZbrvttvjkk0+idevWsWzZspg8eXL07NkztcThvHnzYsGCBfH8889HXl5ekccsKqGqdevWRdb9/PPP449//GM899xzsXDhwiLPLSLiiy++iIhILXm6rqLKPv7441ixYkWxMUb8tEzvuolSpfFzxpV121g3+Soiolq1arHddtvFzJkz08rvvvvuuPfee+Ojjz6K/Pz8tG3r3sdPP/00GjduXGhJyp+r4Pq3bdu20LY2bdpEpUqVCsUcUbLxbWNKe62//PLLEsVdUDZz5szo1KlTKv6inuGddtopLXHtv//9b+Tn58fo0aNj9OjRJYq7JMp6nctLwdKi69ppp50iIjbpcYvzc5+zl156KYYOHRpvvPFG/Pjjj2nb1n1uNja+PPPMMyWKryz9++fYWJ9dX1nGxYKfLSVd/hwAAIDMINENAAAAfqHWnZmnJOXrKvgF7y233BK77LJLkXWaNGmSqtuzZ8/4+OOP4/e//3106tQp6tSpE5UrV44xY8bEQw89VChBZUNxrJu4VPBL6e+//36jMRencePGceyxx8axxx4bJ598cjz00EPx9NNPR9++fcvc5hdffBFTp06NJEmKTWSaMGFCoVl5atasWWxCXUmceuqpMXjw4HjppZfigAMOiPHjx0flypXTzqWs92Ndxf1if82aNYXKChLTnnnmmWLvaVHJK8X54YcfNpiMUGBDfWPy5Mlx/PHHx+677x4jRoyIbbbZJnJycmLt2rXRq1evQud/6qmnxm233Rbjx4+Pa6+9NiZPnhxLly5Nm62voF8ecMABcckll5T4fIqazW3p0qWx7777xrJly2Lw4MHRvn37yM3NjUqVKsUNN9wQL730UonbX1+SJNG+ffu47bbbiq1TkutbnJ8zrpTWbbfdFhdeeGH07NkzBg0aFE2aNIns7OyYPXt29O/ff6P9uCKVZHwraxvl0XZZFRyjb9++ac/HugpmU9yUSjNG/RKP+3Pu/VtvvRU9e/aMli1bxo033hjbbrttVK9ePbKysuKEE04ol+dmU/TBDSWU/dzrW5ZxseBny88ZLwEAANj8JLoBAADAr1CrVq0iomSJWe+//3689957ceWVV8bVV1+dtm3UqFE/K46CBKnyWg6ta9eu8dBDD8Xs2bN/VjtjxoyJJEni/vvvj7p16xbafsUVV8QDDzxQKNHt5zrppJPi4osvjvHjx8dee+0Vjz76aBx44IHRuHHjVJ3yuB8Fs919//33aTPfFTWzUatWreLZZ5+NZs2aFTkrUmnMmjUr1qxZs9FlXCM23DcefPDByMnJialTp6Ylms2YMaPItnbeeefYeeedY8KECXHNNdfE+PHjo27dutGnT59Unby8vKhbt24sXrz4ZyUrRkT8/e9/j//973/xwAMPxGmnnZa27Yorrkj73KJFi4j4aSat9RVV1qpVq5g3b1706NHjZy3ZuSnNnDkzVq1alTar28qVK2PmzJlpMzQ9+OCD0aJFi3jmmWfSzuXZZ58t1Gbr1q1jypQp8d13321wVrfSzs5UMIPWRx99VGjbjBkzIj8/v0wzmG1qBTF99NFHsf3226dt+89//pNWp+C/M2bMKLZugZYtW0ZWVlasWrXqZz8H6yrtda5Xr16Ry1AXNUaV5J4XzGK6rvWvU8Fxi0quLetxN4WHHnoo1q5dG88880zaDHDLli1Lm80tIn18Wb8fFzW+/Fwbuibr/txZ3/rXd90+u771+2xE2cbFgplaS/LzCAAAgMyRmd+GAQAAAJvUQQcdFA0bNowbb7yxyF86r1ixIpYsWRIR/zezy/ozuXz44Yfx+OOP/6w48vLyom3btvH666+XeJ+XX345VqxYUag8Pz8/nnjiiYgoemmzksrPz4+xY8dG+/bt48wzz4xjjjmm0J8TTzwxPvjgg3jrrbfKfJyi5OXlxcEHHxyTJ0+OiRMnxuLFiwvNqlQe96NglroXX3wxrXzYsGGF6p5yyikREXH55ZfH2rVrC20vzbKlBfe5W7duG627ob5RuXLlyMrKSpu5KEmSuPbaa4ttr1+/fvHll1/GQw89FC+99FIcf/zxkZOTk9peqVKlOPnkk+PNN9+MRx99tMg2ilomtijF3aPnn38+3njjjbSyTp06RePGjWPs2LFpSSpLly6Ne++9t1Dbp556anz77bfFzlxUmvuxqSxevDjuvvvutLK77747Fi9eHEcccUSqrOA+rnud1qxZEzfeeGOhNk8++eSIiPjDH/5QaMaqdfevVatWRJR8lsiGDRvGnnvuGU888UR8+OGHaW3ecMMNERFx5JFHlqitzalPnz6RlZUVt9xyS9rSvXPmzIkxY8ZE8+bNo2PHjml1b7vttrRn+J133ik0BtSvXz8OOeSQmDx5cpHPXpIkMW/evFLHW9rr3Lp161iyZEm8+eabqbL8/PwYPnx4obZLcs8nTpwY33zzTerzqlWrYvjw4VG5cuU47LDD0o47Y8aMtGTplStXxl133VWm424KxY0v119/faFno3fv3hERMWLEiLRtH3zwQTz33HPlHtuGrsm2224bVapUKdTn/vWvfxXqa7vttls0bdo0xowZE/Pnz0+VL168uNzGxddffz2qVKkSe+2118ZPDAAAgIxhRjcAAAD4FapZs2aMHz8+jjjiiNhhhx3i9NNPj5YtW8bChQtjxowZMXny5Hj88cdjv/32izZt2kTbtm3j5ptvjuXLl8cOO+wQn3zySdx3333Rvn37ImfdKY1jjz02rrnmmpgzZ07azGXFufXWW+O1116L3r17x6677hp16tSJb7/9Nh577LGYNm1adO/ePQ499NAyx/P888/H119/HWeccUaxdY4++ugYMmRIjB49Ojp37lzmYxWlX79+8be//S0uvPDCqFOnTlpiUESUy/048cQT4/LLL48BAwbEjBkzol69evHss8+mJRQU6Ny5cwwZMiSGDBkSu+yySxx77LHRpEmTmDNnTkybNi2efvrpWLVqVYnO7emnn44GDRpE9+7dS1S/uL5xzDHHxGOPPRY9evSIU089NVavXh1//etfY/ny5cW2dfLJJ8cf/vCHGDhwYOTn5xe5LON1110Xr732Whx33HFx3HHHRdeuXSM7Ozu+/PLLePrpp2O33XaLsWPHbjTuvffeOxo1ahQXXnhhzJo1K5o2bRrTp0+PBx98MNq3bx8ffPBBqm6VKlXi1ltvjZNPPjl23333OOOMM6JKlSoxduzYqF+/fnzxxRdpsyT9/ve/jxdeeCEuvvjieOmll6JHjx5Ru3bt+Oqrr+Lvf/97aqa7irT99tvH1VdfHR9++GHstttuMW3atHjggQdixx13jEGDBqXqHXPMMXHZZZfFwQcfHEcddVQsXrw4HnrooahatWqhNo899tg4/vjjY/z48fHpp59Gnz59YquttopPPvkknnvuuVTyVOfOnaNSpUpx3XXXxQ8//BA1a9aMbbfdNrp06VJsvCNGjIhu3brFPvvsE+eee240atQonnzyyXjuuefipJNOiv3337/8L9LPtMMOO8TFF18cN998c+y7775x/PHHx5IlS2LkyJGxdOnSmDhxYiohascdd4xzzz037rzzzujRo0ccffTRMXfu3Ljzzjtj5513jnfffTet7XvuuSf23nvv2HfffePUU0+Njh07Rn5+fsycOTOmTJkSp556agwZMqTUMZfmOg8YMCCGDRsWRx55ZPz+97+P7OzsePTRR4tc4nKnnXaK3NzcuPvuu6NGjRpRt27daNiwYfTo0SNVp3Xr1tGlS5c4++yzIzc3Nx566KF466234k9/+lNss802qXrnnXde/OUvf4kDDjggzj777Fi1alU8+OCDRS5RXJa+Vh6OPPLIGD58eBxyyCExYMCAyM7OjhdeeCHef//9aNCgQVrdtm3bxoABA2LkyJFxwAEHxJFHHhnz5s2Lu+66Kzp27BjTpk0r15np6tevHy1btoy//OUvsf3228dvfvObqFmzZvTu3Ttq1aoV/fv3j1GjRsWJJ54Y++23X3z66acxZsyY6NChQ7z33nupdipXrhzDhw+P4447Lnbfffc466yzokqVKvHAAw9E/fr146uvvko7bmnHxSRJ4tlnn41evXqlkvMAAAD4hUgAAACAX5QxY8YkEZFMnTq10LaISPr161eovF+/fklRXwN88MEHycknn5w0adIkqVq1atKwYcNkjz32SIYOHZosWLAgVW/WrFnJMccckzRo0CCpXr160rlz52Ty5MnJVVddlURE8sUXX2z0WMXFN3v27KRKlSrJrbfeWmTczZs3Tyv797//nVxwwQVJp06dkoYNGyZVqlRJ6tSpk3Tt2jUZNmxY8uOPP6bV79atW1KzZs0i40mSJHUOb731VpIkSXLMMcckEZG8//77xe6TJEnSunXrpE6dOsny5cuTJEmS5s2bJ23btt3gPiWxcuXKpF69eklEJGeeeWaRdUpzP4oqS5Ikef3115M999wzqVatWlK/fv3krLPOSn744Ydi+9CTTz6Z9OzZM9lqq62S7OzspGnTpkmvXr2Se+65J61eQf9c/3hLly5NatasmVx00UUlvhYb6hsjR45M2rRpk1SrVi1p1KhRctZZZyULFiwoNv4kSZLDDjssiYikVatWxR5z2bJlydChQ5N27dolOTk5Sa1atZIdd9wxOfPMM5PXX3+90HkW9RwmSZK89957yUEHHZTUrVs3qVWrVtKtW7fklVdeKfb5ePjhh5P27dsn2dnZyTbbbJMMGTIkmTx5chIRyaRJk9Lqrl69OhkxYkTSqVOnpEaNGkmNGjWSli1bJieddFLy3HPPFXtuG4q9vMaV5s2bJ926dUumTZuWdO/ePalRo0ZSt27dpG/fvsm3336bVnfNmjXJ9ddfn2y//fZJdnZ20qxZs+Tiiy9O/vOf/yQRkVx11VVp9deuXZvceeedSceOHZPq1asntWrVStq3b58MGTIkrd7YsWOTNm3aJFWrVt1gf1jX9OnTk8MPPzzVv3fcccfkpptuStasWbPRc97YdVpfcc/kF198UeR5J8lP49j6Y2GS/PQc7LLLLkm1atWS3Nzc5IADDkheeeWVQvXWrl2bXHvttUmzZs2S7OzspG3btsmECROKjWXevHnJRRddlLRq1SqpVq1aUqdOnaRdu3bJoEGDko8++ihVb2PPwfpKep2TJEmeeuqpZOedd06ys7OTxo0bJ3/4wx+SGTNmFHmNnnrqqaRjx45JtWrVkohIunXrliRJkkydOjWJiGTMmDHJiBEjkpYtWybZ2dlJy5Ytkz//+c9Fxjh27NikdevWSdWqVZMWLVokN910U/L3v/891c76dUvT14rrP+vGub6CZ2pdjz/+eLLrrrsmNWrUSOrXr58cf/zxyZdffllk3TVr1iRDhgxJttlmmyQ7Oztp3759MmnSpOTCCy9MIiL57rvvNhpfkhTu38X11zfeeCPZc889kxo1aiQRkdZvlyxZkpxxxhlJvXr1kurVqyd777138tprrxV73MceeyzVB5o2bZpcccUVyfPPP1/ktSrNuPjyyy8nEZE8+eSTRZ4rAAAAmSsrSdab4xwAAABgMzv77LPj+eefj//+979pszn1798/Xn755Zg1a1bFBUepjB07Nk477bT44osvokWLFqnyESNGxB//+Mf49NNPSzRzX4Hi+savwbBhw+Kiiy6Kf//739G1a9eKDqdEWrRoES1atIiXX365okOBePnll6N79+4xZsyY6N+/f0WHk1F69+4dL730UixevDg1+9+vxZFHHhlff/11vPXWW+U6ox0AAACbXqWKDgAAAABg6NChsWDBghgzZkxFh8ImsGLFirjxxhvj4osvLlWSW8Svo2+sWrUq1q5dm1a2dOnSuOuuu6J+/fqx6667VlBkwC/dihUrCpW9//778cwzz0SPHj1+dUlu7777bkyZMiWGDRsmyQ0AAOAXqEpFBwAAAADQsGHDWLRoUUWHwSZSvXr1mDNnTpn2/TX0jZkzZ8bBBx8cJ5xwQmy77bYxZ86cGDduXHzxxRdxzz33RHZ2dkWHCPxCjRs3LsaPHx+HHnpo5OXlxYwZM2LkyJGRnZ0dQ4cOrejwNruOHTtGfn5+RYcBAABAGUl0AwAAAIAKlJeXF127do2JEyfG3Llzo0qVKtG+ffu48cYb47jjjqvo8IBfsF133TUef/zxuP322+P777+P3Nzc6NGjR1x11VXRsWPHig4PAAAASiUrSZKkooMAAAAAAAAAAACA4lSq6AAAAAAAAAAAAABgQyS6AQAAAAAAAAAAkNEkugEAAAAAAAAAAJDRJLoBAAAAAAAAAACQ0SS6AQAAAAAAAAAAkNEkugEAAAAAAAAAAJDRJLoBAAAAAAAAAACQ0SS6AQAAAAAAAAAAkNEkugEAAAAAAAAAAJDR/j9p21e3jfcvmgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simalo.run(args=tcr_args) # 변경한 tcr_args 반영\n",
    "# simalo.data: TCR asset의 결과물입니다. \n",
    "# simalo.config: TCR asset의 결과 config입니다. \n",
    "\n",
    "# tcr asset의 결과 dataframe은 data_tcr['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0370-76a0-4a67-8f18-fbc0c78be45d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Inference workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c4f2ad-3672-47c4-ab90-f242351868a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 04:21:25,304][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,314][PROCESS][INFO]:  Skip loading external data. << /nas001/users/yoonji.suh/tcr_test_20231016/inf/ >> \n",
      " << inf >> already exists in << /home/jovyan/project/alo_dev/tcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,320][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,323][PROCESS][INFO]: << input >> asset had already been created at 2023-11-08 01:28:00.751822\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,325][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:25,327][PROCESS][INFO]: Now << local >> asset_source_code mode: <preprocess> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,328][PROCESS][INFO]: Start setting-up << inference >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,330][PROCESS][INFO]: << inference >> asset had already been created at 2023-11-08 01:28:18.350955\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,332][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,334][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,335][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,338][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 1 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:25,341][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,344][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,347][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Inference 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "simalo = SimpleALO(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff83d2d-96f6-4b76-aae2-cde768ccb459",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Input asset \n",
    "##### Input asset의 arguments 수정 및 확인\n",
    "- 필요한경우 input_args의 항목을 ***input_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd4936e-5a10-4912-9be7-b584bbd46faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'inf',\n",
       " 'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       " 'use_all_x': False,\n",
       " 'y_column': None,\n",
       " 'groupkey_columns': None,\n",
       " 'drop_columns': None,\n",
       " 'time_column': None,\n",
       " 'concat_dataframes': True,\n",
       " 'encoding': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "input_args =  simalo.get_args(step=0)\n",
    "\n",
    "# 아래 주석을 풀어 input_args를 원하는 값으로 수정합니다. \n",
    "# input_args['x_columns'] = ['']\n",
    "input_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ebf68-4622-431b-a458-2f6549949457",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b327df2-05c3-4538-abab-2c54bab36358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-08 04:21:25,374][USER][INFO][inference_pipeline][input]: >> Load path : ['/home/jovyan/project/alo_dev/tcr/alo//input/inf/']\n",
      "[2023-11-08 04:21:25,388][USER][INFO][inference_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/project/alo_dev/tcr/alo//input/inf/iris.csv)\n",
      "[2023-11-08 04:21:25,392][USER][INFO][inference_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-08 04:21:25,395][USER][INFO][inference_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[2023-11-08 04:21:25,398][USER][INFO][inference_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/project/alo_dev/tcr/alo//input/inf/iris.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 04:21:25,370][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:25\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_config.pkl\n",
      "\u001b[94m[2023-11-08 04:21:25,406][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:25\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,409][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: input\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  input_x0  input_x1  input_x2  input_x3     target\n",
       "0         147       6.5       3.0       5.2       2.0  virginica\n",
       "1         148       6.2       3.4       5.4       2.3  virginica\n",
       "2         149       5.9       3.0       5.1       1.8  virginica"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simalo.run(args=input_args) # 변경한 input_args 반영\n",
    "# simalo.data: input asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# simalo.config: input asset의 결과 config입니다. 다음 asset실행 시 필요합니다.\n",
    "\n",
    "# input asset의 결과 dataframe은 data_input['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed2281-711e-4284-b9ff-6f35a9577f7c",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 2. Preprocess asset \n",
    "##### Preprocess asset의 args수정 및 확인\n",
    "- 필요한경우 preprocess_args의 항목을 ***preprocess_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947687b4-7573-4557-9f39-5e87256d34f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handling_encoding_y_column': None,\n",
       " 'handling_encoding_y': None,\n",
       " 'handling_missing': 'dropna',\n",
       " 'handling_scaling_x': 'none',\n",
       " 'drop_duplicate_time': True,\n",
       " 'load_train_preprocess': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference  asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "preprocess_args = simalo.get_args(step=1)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess_args 수정합니다. \n",
    "# preprocess_args['handling_missing'] = 'interpolation'\n",
    "preprocess_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed3255-a09f-460c-9ea6-b2969547df81",
   "metadata": {},
   "source": [
    "##### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5cc44ca-e531-4d4b-8b36-481f10aa75e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_data.pkl\n",
      "\u001b[92m[2023-11-08 04:21:25,449][ASSET][INFO][inference_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,450][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:25\n",
      "- current step      : preprocess\n",
      "- asset branch.     : tcr\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_encoding_y_column', 'handling_encoding_y', 'handling_missing', 'handling_scaling_x', 'drop_duplicate_time', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'] \n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "\u001b[94m[2023-11-08 04:21:25,471][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:25\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:25,476][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  input_x2  input_x3  input_x0_nan  input_x1_nan  \\\n",
       "0       6.5       3.0       5.2       2.0           6.5           3.0   \n",
       "1       6.2       3.4       5.4       2.3           6.2           3.4   \n",
       "2       5.9       3.0       5.1       1.8           5.9           3.0   \n",
       "\n",
       "   input_x2_nan  input_x3_nan  \n",
       "0           5.2           2.0  \n",
       "1           5.4           2.3  \n",
       "2           5.1           1.8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simalo.run(args=preprocess_args) # 변경한 preprocess_args 반영\n",
    "# simalo.data: preprocess asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# simalo.config: preprocess asset의 결과 config입니다. 다음 asset실행 시 필요합니다. \n",
    "\n",
    "# preprocess asset의 결과 dataframe은 simalo.data['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab9a71-b432-42b5-872c-4ebf7e69eafc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3. inference asset \n",
    "##### inference asset의 args수정 및 확인\n",
    "- 필요한경우 TCR_args의 항목을 ***TCR_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7346ec19-6e57-4aab-b558-357d0e10a3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification', 'run_shapley': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "tcr_args = simalo.get_args(step=2)\n",
    "\n",
    "# 아래 주석을 풀어 tcr_args를 수정합니다. \n",
    "# tcr_args['model_type'] = \n",
    "tcr_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79326071-d505-4ed2-9f8b-a4fbdad14f02",
   "metadata": {},
   "source": [
    "##### inference asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90de8db-0682-4c6e-b2e7-60a5dd6024fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "\n",
      " ################################### inference_init (sec):  0.0030999183654785156 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-08 04:21:25,522][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 04:21:25\n",
      "- current step      : inference\n",
      "- asset branch.     : main\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'run_shapley'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:25,524][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-08 04:21:25,526][ASSET][INFO][inference_pipeline][inference]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.inference_artifacts/output/inference/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['input_x0', 'input_x2', 'input_x3', 'input_x1'])\n",
      "\u001b[92m[2023-11-08 04:21:25,532][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "[INFO] XAI 분석 시, 활용할 모델을 로드합니다.\n",
      "/home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/model_selection.json\n",
      "[['x0', 'input_x0_nan'], ['x1', 'input_x1_nan'], ['x2', 'input_x2_nan'], ['x3', 'input_x3_nan']]\n",
      "[['x0', 'input_x0_nan'], ['x1', 'input_x1_nan'], ['x2', 'input_x2_nan'], ['x3', 'input_x3_nan']]\n",
      "모델을 Load 완료 하였습니다. (모델 위치: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top0.pkl)\n",
      "[INFO] SHAP 기반 XAI 분석을 진행합니다.\n",
      "[INFO] Summary_plot for Inference data 를 저장했습니다. (1/2)\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/inference_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/inference_config.pkl\n",
      "\n",
      " ################################### inference_user_run (sec):  0.6307649612426758 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-08 04:21:26,158][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 04:21:26\n",
      "- current step      : inference\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 04:21:26,160][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: inference\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "      <th>input_x0_nan_shapley</th>\n",
       "      <th>input_x1_nan_shapley</th>\n",
       "      <th>input_x2_nan_shapley</th>\n",
       "      <th>input_x3_nan_shapley</th>\n",
       "      <th>pred_</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.583817</td>\n",
       "      <td>-0.214722</td>\n",
       "      <td>-1.14936</td>\n",
       "      <td>-1.121901</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0004328007534890143, 0.0009738324940228138,...</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.998593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-0.440786</td>\n",
       "      <td>0.347757</td>\n",
       "      <td>-1.22977</td>\n",
       "      <td>-1.205631</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.001161255681588001, 0.001383302688220785, 0...</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.126765</td>\n",
       "      <td>-0.224708</td>\n",
       "      <td>-1.22536</td>\n",
       "      <td>-1.186890</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.002881650240370401, 0.01756998171034897, 0....</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>0.979548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  input_x2  input_x3  input_x0_nan  input_x1_nan  \\\n",
       "0       6.5       3.0       5.2       2.0           6.5           3.0   \n",
       "1       6.2       3.4       5.4       2.3           6.2           3.4   \n",
       "2       5.9       3.0       5.1       1.8           5.9           3.0   \n",
       "\n",
       "   input_x2_nan  input_x3_nan  input_x0_nan_shapley  input_x1_nan_shapley  \\\n",
       "0           5.2           2.0             -0.583817             -0.214722   \n",
       "1           5.4           2.3             -0.440786              0.347757   \n",
       "2           5.1           1.8             -0.126765             -0.224708   \n",
       "\n",
       "   input_x2_nan_shapley  input_x3_nan_shapley  pred_  \\\n",
       "0              -1.14936             -1.121901      2   \n",
       "1              -1.22977             -1.205631      2   \n",
       "2              -1.22536             -1.186890      2   \n",
       "\n",
       "                                    prediction_score    prob_0    prob_1  \\\n",
       "0  [0.0004328007534890143, 0.0009738324940228138,...  0.000433  0.000974   \n",
       "1  [0.001161255681588001, 0.001383302688220785, 0...  0.001161  0.001383   \n",
       "2  [0.002881650240370401, 0.01756998171034897, 0....  0.002882  0.017570   \n",
       "\n",
       "     prob_2  \n",
       "0  0.998593  \n",
       "1  0.997455  \n",
       "2  0.979548  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2700x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simalo.run(args=tcr_args) # 변경한 preprocess_args 반영\n",
    "# simalo.data: TCR asset의 결과물입니다. \n",
    "# simalo.config: TCR asset의 결과 config입니다. \n",
    "\n",
    "# tcr asset의 결과 dataframe은 data_tcr['dataframe']으로 확인할 수 있습니다. \n",
    "simalo.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ce7f7-0ec3-42af-b5d9-fd1f8b32b0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
