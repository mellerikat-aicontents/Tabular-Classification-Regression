{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba485ca-6d99-47e1-9dc8-edaa1fed8e6b",
   "metadata": {},
   "source": [
    "아래는 ALO 기본 설정 및 라이브러리 설치 코드입니다. 설치 에러가 발생하면 아래 셀을 재실행 하고, 지속적으로 문제가 있을 시 문의바랍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aad15e2-f671-4c83-b305-fcca2154e45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "os.chdir(os.path.abspath(os.path.join('./alo')))\n",
    "from src.alo import ALO\n",
    "from src.alo import AssetStructure\n",
    "alo = ALO(); alo.preset(); pipelines = list(alo.asset_source.keys())\n",
    "from src.external import external_load_data, external_save_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce91a6-d23b-4631-92a2-12e15b1b328f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90542e06-7111-44ba-8a42-6c4f1400fd2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-02 09:27:36,967][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:36,970][PROCESS][INFO]:  Skip loading external data. << /nas001/users/yoonji.suh/tcr_test_20231016/train_multiclass/ >> \n",
      " << train_multiclass >> already exists in << /home/jovyan/project/alo_test_20231102/tcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:36,973][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:36,976][PROCESS][INFO]: Now << local >> asset_source_code mode: <input> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:36,980][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:36,983][PROCESS][INFO]: Now << local >> asset_source_code mode: <preprocess> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:36,986][PROCESS][INFO]: Start setting-up << sampling >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:36,989][PROCESS][INFO]: Now << local >> asset_source_code mode: <sampling> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:36,993][PROCESS][INFO]: Start setting-up << train >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:36,996][PROCESS][INFO]: Start renewing asset : /home/jovyan/project/alo_test_20231102/tcr/alo/assets/train\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,546][PROCESS][INFO]: /home/jovyan/project/alo_test_20231102/tcr/alo/assets/train successfully pulled.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,553][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,557][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,561][PROCESS][INFO]: >>> Ignored installing << numpy==1.25.2 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,565][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,568][PROCESS][INFO]: >>> Ignored installing << scikit-learn >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,572][PROCESS][INFO]: >>> Ignored installing << matplotlib >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,575][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,579][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,583][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,586][PROCESS][INFO]: ======================================== Start dependency installation : << preprocess >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,590][PROCESS][INFO]: Start checking existence & installing package - category_encoders | Progress: ( 2 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,594][PROCESS][INFO]: [OK] << category_encoders >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,598][PROCESS][INFO]: ======================================== Start dependency installation : << sampling >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,601][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 | Progress: ( 3 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,605][PROCESS][INFO]: [OK] << numpy==1.25.2 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,609][PROCESS][INFO]: Start checking existence & installing package - scikit-learn | Progress: ( 4 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,613][PROCESS][INFO]: [OK] << scikit-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,617][PROCESS][INFO]: Start checking existence & installing package - umap-learn | Progress: ( 5 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,621][PROCESS][INFO]: [OK] << umap-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,624][PROCESS][INFO]: Start checking existence & installing package - matplotlib | Progress: ( 6 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,628][PROCESS][INFO]: [OK] << matplotlib >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,632][PROCESS][INFO]: ======================================== Start dependency installation : << train >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,636][PROCESS][INFO]: Start checking existence & installing package - seaborn | Progress: ( 7 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,640][PROCESS][INFO]: [OK] << seaborn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,644][PROCESS][INFO]: Start checking existence & installing package - shap | Progress: ( 8 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,648][PROCESS][INFO]: [OK] << shap >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,652][PROCESS][INFO]: Start checking existence & installing package - lightgbm | Progress: ( 9 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,656][PROCESS][INFO]: [OK] << lightgbm >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,660][PROCESS][INFO]: Start checking existence & installing package - catboost | Progress: ( 10 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,664][PROCESS][INFO]: [OK] << catboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,668][PROCESS][INFO]: Start checking existence & installing package - ngboost | Progress: ( 11 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:37,672][PROCESS][INFO]: [OK] << ngboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,676][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,680][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 --force-reinstall | Progress: ( 12 / 12 total packages ) \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:37,684][PROCESS][INFO]: >>> Start installing package - numpy==1.25.2 --force-reinstall\u001b[0m\n",
      "Collecting numpy==1.25.2\n",
      "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed numpy-1.25.2\n",
      "\u001b[94m[2023-11-02 09:27:50,423][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Train 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "external_load_data(pipelines[0], alo.external_path, alo.external_path_permission, alo.control['get_external_data'])\n",
    "pipeline = pipelines[0]\n",
    "alo.install_steps(pipeline, alo.control[\"get_asset_source\"])\n",
    "# 초기 data structure 구성\n",
    "envs, args, data, config = {}, {}, {}, {}\n",
    "asset_structure = AssetStructure(envs, args, data, config); alo.set_proc_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb217e-4e1b-468f-babd-d1bb1f676225",
   "metadata": {},
   "source": [
    "### 1. Input asset \n",
    "##### Input asset의 arguments 수정 및 확인\n",
    "- 필요한경우 input_args의 항목을 ***input_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9aaa50-4c07-46f7-b00e-bc2fec1436f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'train_multiclass',\n",
       " 'x_columns': ['input_x0', 'input_x1'],\n",
       " 'use_all_x': False,\n",
       " 'y_column': 'target',\n",
       " 'groupkey_columns': None,\n",
       " 'drop_columns': None,\n",
       " 'time_column': None,\n",
       " 'concat_dataframes': True,\n",
       " 'encoding': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "step = 0 \n",
    "input_args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 input_args를 원하는 값으로 수정합니다. \n",
    "input_args['x_columns'] = ['input_x0','input_x1']\n",
    "input_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f198b5-2888-4c28-8ca1-c194af431d54",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b3b07b-20d9-4d1d-9433-efa2705ba138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-02 09:27:51,585][USER][INFO][train_pipeline][input]: >> Load path : ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/train_multiclass/']\n",
      "[2023-11-02 09:27:51,602][USER][INFO][train_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/project/alo_test_20231102/tcr/alo//input/train_multiclass/iris.csv)\n",
      "[2023-11-02 09:27:51,607][USER][INFO][train_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-02 09:27:51,611][USER][INFO][train_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[2023-11-02 09:27:51,614][USER][INFO][train_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/train_multiclass/iris.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-02 09:27:51,581][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:27:51\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_2.0\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/input_data.pkl\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/input_config.pkl\n",
      "\u001b[94m[2023-11-02 09:27:51,621][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-02 09:27:51\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:51,624][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: input\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  input_x0  input_x1  input_x2  input_x3  target\n",
       "0           0       5.1       3.5       1.4       0.2  setosa\n",
       "1           1       4.9       3.0       1.4       0.2  setosa\n",
       "2           2       4.7       3.2       1.3       0.2  setosa\n",
       "3           3       4.6       3.1       1.5       0.2  setosa\n",
       "4           4       5.0       3.6       1.4       0.2  setosa\n",
       "5           5       5.4       3.9       1.7       0.4  setosa\n",
       "6           6       4.6       3.4       1.4       0.3  setosa\n",
       "7           7       5.0       3.4       1.5       0.2  setosa\n",
       "8           8       4.4       2.9       1.4       0.2  setosa\n",
       "9           9       4.9       3.1       1.5       0.1  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.args = input_args # 변경한 input_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: input asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: input asset의 결과 config입니다. 다음 asset실행 시 필요합니다.\n",
    "\n",
    "# input asset의 결과 dataframe은 data_input['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1056a2-0146-4612-b32b-eda9b9eef0eb",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 2. Preprocess asset \n",
    "##### Preprocess asset의 args수정 및 확인\n",
    "- 필요한경우 preprocess_args의 항목을 ***preprocess_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ee6653-d1aa-4f0a-91bc-3bd60c158a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handling_encoding_y_column': 'target',\n",
       " 'handling_encoding_y': 'label',\n",
       " 'handling_missing': 'dropna',\n",
       " 'handling_scaling_x': 'none',\n",
       " 'drop_duplicate_time': True,\n",
       " 'load_train_preprocess': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "step = 1 \n",
    "preprocess_args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess_args 수정합니다. \n",
    "# preprocess_args['handling_missing'] = 'interpolation'\n",
    "preprocess_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae00130-ccf8-4ce4-988d-5cc978cb0d28",
   "metadata": {},
   "source": [
    "##### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da6ed5f-5324-4775-b748-f4a8592b6aea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/input_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/input_data.pkl\n",
      "\u001b[92m[2023-11-02 09:27:53,508][ASSET][INFO][train_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:53,510][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:27:53\n",
      "- current step      : preprocess\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_encoding_y_column', 'handling_encoding_y', 'handling_missing', 'handling_scaling_x', 'drop_duplicate_time', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "target column : label Encoder saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/preprocess/\n",
      "['input_x0_nan', 'input_x1_nan'] target_encoded_nan\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/preprocess_data.pkl\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/preprocess_config.pkl\n",
      "\u001b[94m[2023-11-02 09:27:53,533][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-02 09:27:53\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:53,536][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>target</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  target  target_encoded  input_x0_nan  input_x1_nan  \\\n",
       "0       5.1       3.5  setosa               0           5.1           3.5   \n",
       "1       4.9       3.0  setosa               0           4.9           3.0   \n",
       "2       4.7       3.2  setosa               0           4.7           3.2   \n",
       "3       4.6       3.1  setosa               0           4.6           3.1   \n",
       "4       5.0       3.6  setosa               0           5.0           3.6   \n",
       "5       5.4       3.9  setosa               0           5.4           3.9   \n",
       "6       4.6       3.4  setosa               0           4.6           3.4   \n",
       "7       5.0       3.4  setosa               0           5.0           3.4   \n",
       "8       4.4       2.9  setosa               0           4.4           2.9   \n",
       "9       4.9       3.1  setosa               0           4.9           3.1   \n",
       "\n",
       "   target_encoded_nan  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "5                   0  \n",
       "6                   0  \n",
       "7                   0  \n",
       "8                   0  \n",
       "9                   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.args = preprocess_args # 변경한 preprocess_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: preprocess asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: preprocess asset의 결과 config입니다. 다음 asset실행 시 필요합니다. \n",
    "\n",
    "# preprocess asset의 결과 dataframe은 data_preprocess['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd960780-4d1f-43eb-b28d-561031203f53",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 3. Sampling asset \n",
    "##### Sampling asset의 args수정 및 확인\n",
    "- 필요한경우 Sampling_args의 항목을 ***sampling_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3385afc-3bda-426f-9a33-ac41d0c2288c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sampling_type': 'none',\n",
       " 'sampling_method': 'random',\n",
       " 'label_sampling': False,\n",
       " 'ignore_label_class': None,\n",
       " 'negative_target_class': None,\n",
       " 'label_sampling_num_type': None,\n",
       " 'label_sampling_num': None,\n",
       " 'sampling_groupkey_columns': None,\n",
       " 'sampling_num_type': 'ratio',\n",
       " 'sampling_num': 0.8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "step = 2 \n",
    "sampling_args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess_args 수정합니다. \n",
    "# sampling_args['sampling_type'] = 'under'\n",
    "sampling_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fde40b-fb56-47aa-ab6d-4cc95957fe00",
   "metadata": {},
   "source": [
    "##### Sampling asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af2307c-924c-4f26-9c81-d8044b9ba3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/envs/tcr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/preprocess_data.pkl\n",
      "\u001b[94m[2023-11-02 09:27:58,991][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:27:58\n",
      "- current step      : sampling\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['sampling_type', 'sampling_method', 'label_sampling', 'ignore_label_class', 'negative_target_class', 'label_sampling_num_type', 'label_sampling_num', 'sampling_groupkey_columns', 'sampling_num_type', 'sampling_num'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:27:58,994][ASSET][INFO][train_pipeline][sampling]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/sampling/\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/sampling_data.pkl\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/sampling_config.pkl\n",
      "\u001b[94m[2023-11-02 09:27:58,999][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-02 09:27:58\n",
      "- current step      : sampling\n",
      "- save config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:27:59,001][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: sampling\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>target</th>\n",
       "      <th>target_encoded</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  target  target_encoded  input_x0_nan  input_x1_nan  \\\n",
       "0       5.1       3.5  setosa               0           5.1           3.5   \n",
       "1       4.9       3.0  setosa               0           4.9           3.0   \n",
       "2       4.7       3.2  setosa               0           4.7           3.2   \n",
       "3       4.6       3.1  setosa               0           4.6           3.1   \n",
       "4       5.0       3.6  setosa               0           5.0           3.6   \n",
       "5       5.4       3.9  setosa               0           5.4           3.9   \n",
       "6       4.6       3.4  setosa               0           4.6           3.4   \n",
       "7       5.0       3.4  setosa               0           5.0           3.4   \n",
       "8       4.4       2.9  setosa               0           4.4           2.9   \n",
       "9       4.9       3.1  setosa               0           4.9           3.1   \n",
       "\n",
       "   target_encoded_nan  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "5                   0  \n",
       "6                   0  \n",
       "7                   0  \n",
       "8                   0  \n",
       "9                   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.args = sampling_args # 변경한 sampling_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: sampling asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: sampling asset의 결과 config입니다. 다음 asset실행 시 필요합니다. \n",
    "\n",
    "# sampling asset의 결과 dataframe은 data_sampling['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24997c79-babb-4445-b1ff-e2493dfdaad6",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 4. train asset \n",
    "##### train asset의 args수정 및 확인\n",
    "- 필요한경우 TCR_args의 항목을 ***TCR_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e0840b-50ba-4f6b-8998-8b28a5bfd5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification',\n",
       " 'data_split_method': 'cross_validate',\n",
       " 'evaluation_metric': 'accuracy',\n",
       " 'model_list': ['lgb', 'rf', 'cb'],\n",
       " 'num_hpo': 3,\n",
       " 'param_range': {'rf': {'max_depth': 6, 'n_estimators': [300, 500]},\n",
       "  'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "  'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "  'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "  'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}},\n",
       " 'shap_ratio': 1.0,\n",
       " 'evaluation_report': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "step = 3 \n",
    "tcr_args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 tcr_args를 수정합니다. \n",
    "# tcr_args['model_list'] = ['lgb']\n",
    "tcr_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29407e1f-58b2-4c97-b58a-6d684ad47167",
   "metadata": {},
   "source": [
    "##### train asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e964dac8-836a-4b4c-b2b1-d183377d4068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/sampling_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/sampling_data.pkl\n",
      "\u001b[92m[2023-11-02 09:28:03,375][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:03,380][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:03,382][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:28:03\n",
      "- current step      : train\n",
      "- asset branch.     : tcr_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'data_split_method', 'evaluation_metric', 'model_list', 'num_hpo', 'param_range', 'shap_ratio', 'evaluation_report'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:03,385][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:03,388][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:03,391][ASSET][INFO][train_pipeline][train]: Successfully got << report path >> for saving your << report.html >> file: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/report/\u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['input_x0', 'target', 'input_x1', 'target_encoded', 'target_encoded_nan'])\n",
      "[INFO] 모델 학습을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 0th-fold RandomForestClassifier_set0 모델을 학습합니다.(1/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set0 모델을 학습합니다.(2/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set0 모델을 학습합니다.(3/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set0 모델을 학습합니다.(4/36)\n",
      "[INFO] 0th-fold RandomForestClassifier_set1 모델을 학습합니다.(5/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set1 모델을 학습합니다.(6/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set1 모델을 학습합니다.(7/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set1 모델을 학습합니다.(8/36)\n",
      "[INFO] 0th-fold RandomForestClassifier_set2 모델을 학습합니다.(9/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set2 모델을 학습합니다.(10/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set2 모델을 학습합니다.(11/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set2 모델을 학습합니다.(12/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set0 모델을 학습합니다.(13/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set0 모델을 학습합니다.(14/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set0 모델을 학습합니다.(15/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set0 모델을 학습합니다.(16/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set1 모델을 학습합니다.(17/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set1 모델을 학습합니다.(18/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set1 모델을 학습합니다.(19/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set1 모델을 학습합니다.(20/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set2 모델을 학습합니다.(21/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set2 모델을 학습합니다.(22/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set2 모델을 학습합니다.(23/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set2 모델을 학습합니다.(24/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set0 모델을 학습합니다.(25/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set0 모델을 학습합니다.(26/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set0 모델을 학습합니다.(27/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set0 모델을 학습합니다.(28/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set1 모델을 학습합니다.(29/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set1 모델을 학습합니다.(30/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set1 모델을 학습합니다.(31/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set1 모델을 학습합니다.(32/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set2 모델을 학습합니다.(33/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set2 모델을 학습합니다.(34/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set2 모델을 학습합니다.(35/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set2 모델을 학습합니다.(36/36)\n",
      "@scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list:   @scoring_classification func. - label list:   {0, 1, 2}  {0, 1, 2}  {0, 1, 2}{0, 1, 2} \n",
      "{0, 1, 2}{0, 1, 2}{0, 1, 2}\n",
      "{0, 1, 2}\n",
      "{0, 1, 2}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] 평가 지표는 ( accuracy ) 를 사용합니다. \n",
      "모델 정보 로그를 저장합니다. (저장위치: /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/model_selection.json)\n",
      "\n",
      "Top 1 model file is saved: /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/best_model_top0.pkl\n",
      "[Score] accuracy: 0.7551\n",
      "[Hyper-parameters] n_estimators: 500, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Top 2 model file is saved: /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/best_model_top1.pkl\n",
      "[Score] accuracy: 0.7483\n",
      "[Hyper-parameters] n_estimators: 400, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Top 3 model file is saved: /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/best_model_top2.pkl\n",
      "[Score] accuracy: 0.7415\n",
      "[Hyper-parameters] n_estimators: 300, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Following model is the best: RandomForestClassifier_set2 / accuracy:0.7551\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[INFO] Summary_plot for Train data 를 저장했습니다.\n",
      "\n",
      "ignore columns와 X로 지정한 데이터 프레임을 합치는 과정중에 에러가 발생했습니다. 확인 부탁드립니다.\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/train_data.pkl\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/train_pipeline/train_config.pkl\n",
      "\u001b[94m[2023-11-02 09:28:07,624][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-02 09:28:07\n",
      "- current step      : train\n",
      "- save config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type', 'feature_dict'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:07,626][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x0_nan_shapley</th>\n",
       "      <th>input_x1_nan_shapley</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "      <th>pred_target_encoded_nan</th>\n",
       "      <th>pred_target_encoded_nan_best0</th>\n",
       "      <th>pred_target_encoded_nan_best1</th>\n",
       "      <th>pred_target_encoded_nan_best2</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-0.129990</td>\n",
       "      <td>-0.208464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.692516</td>\n",
       "      <td>0.303110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.196202</td>\n",
       "      <td>-0.443213</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278438</td>\n",
       "      <td>0.719941</td>\n",
       "      <td>0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-0.212571</td>\n",
       "      <td>-0.127579</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.212953</td>\n",
       "      <td>0.786925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-0.253157</td>\n",
       "      <td>-0.086116</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624968</td>\n",
       "      <td>0.375032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.186774</td>\n",
       "      <td>-0.470278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106986</td>\n",
       "      <td>0.602868</td>\n",
       "      <td>0.290146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.283653</td>\n",
       "      <td>-0.054309</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.366545</td>\n",
       "      <td>0.633244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.056925</td>\n",
       "      <td>-0.282793</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016720</td>\n",
       "      <td>0.776783</td>\n",
       "      <td>0.206497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-0.074796</td>\n",
       "      <td>-0.254380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035048</td>\n",
       "      <td>0.918853</td>\n",
       "      <td>0.046099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.341304</td>\n",
       "      <td>0.315690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.143307</td>\n",
       "      <td>-0.436134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>0.740998</td>\n",
       "      <td>0.106135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0_nan  input_x1_nan  input_x0_nan_shapley  input_x1_nan_shapley  \\\n",
       "0           5.7           2.8             -0.129990             -0.208464   \n",
       "1           5.0           2.3              0.196202             -0.443213   \n",
       "2           6.5           2.8             -0.212571             -0.127579   \n",
       "3           6.3           2.9             -0.253157             -0.086116   \n",
       "4           5.1           2.5              0.186774             -0.470278   \n",
       "5           6.6           3.0             -0.283653             -0.054309   \n",
       "6           5.5           2.5             -0.056925             -0.282793   \n",
       "7           5.5           2.3             -0.074796             -0.254380   \n",
       "8           5.1           3.8              0.341304              0.315690   \n",
       "9           5.2           2.7              0.143307             -0.436134   \n",
       "\n",
       "   target_encoded_nan  pred_target_encoded_nan  pred_target_encoded_nan_best0  \\\n",
       "0                   1                        1                              1   \n",
       "1                   1                        1                              1   \n",
       "2                   1                        2                              2   \n",
       "3                   2                        1                              1   \n",
       "4                   1                        1                              1   \n",
       "5                   1                        2                              2   \n",
       "6                   1                        1                              1   \n",
       "7                   1                        1                              1   \n",
       "8                   0                        0                              0   \n",
       "9                   1                        1                              1   \n",
       "\n",
       "   pred_target_encoded_nan_best1  pred_target_encoded_nan_best2    prob_0  \\\n",
       "0                              1                              1  0.004375   \n",
       "1                              1                              1  0.278438   \n",
       "2                              2                              2  0.000121   \n",
       "3                              1                              1  0.000000   \n",
       "4                              1                              1  0.106986   \n",
       "5                              2                              2  0.000211   \n",
       "6                              1                              1  0.016720   \n",
       "7                              1                              1  0.035048   \n",
       "8                              0                              0  0.994267   \n",
       "9                              1                              1  0.152868   \n",
       "\n",
       "     prob_1    prob_2  \n",
       "0  0.692516  0.303110  \n",
       "1  0.719941  0.001620  \n",
       "2  0.212953  0.786925  \n",
       "3  0.624968  0.375032  \n",
       "4  0.602868  0.290146  \n",
       "5  0.366545  0.633244  \n",
       "6  0.776783  0.206497  \n",
       "7  0.918853  0.046099  \n",
       "8  0.000000  0.005733  \n",
       "9  0.740998  0.106135  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "asset_structure.args = tcr_args # 변경한 sampling_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: TCR asset의 결과물입니다. \n",
    "# asset_structure.config: TCR asset의 결과 config입니다. \n",
    "\n",
    "# tcr asset의 결과 dataframe은 data_tcr['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0370-76a0-4a67-8f18-fbc0c78be45d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Inference workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c4f2ad-3672-47c4-ab90-f242351868a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-02 09:28:07,811][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:07,814][PROCESS][INFO]:  Skip loading external data. << /nas001/users/yoonji.suh/tcr_test_20231016/inf/ >> \n",
      " << inf >> already exists in << /home/jovyan/project/alo_test_20231102/tcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:07,817][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:07,819][PROCESS][INFO]: Now << local >> asset_source_code mode: <input> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:07,822][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:07,824][PROCESS][INFO]: Now << local >> asset_source_code mode: <preprocess> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:07,826][PROCESS][INFO]: Start setting-up << inference >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:07,829][PROCESS][INFO]: Start renewing asset : /home/jovyan/project/alo_test_20231102/tcr/alo/assets/inference\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:08,265][PROCESS][INFO]: /home/jovyan/project/alo_test_20231102/tcr/alo/assets/inference successfully pulled.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,268][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,272][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,276][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,279][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 1 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:08,283][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,287][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,290][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Inference 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "external_load_data(pipelines[1], alo.external_path, alo.external_path_permission, alo.control['get_external_data'])\n",
    "pipeline = pipelines[1]\n",
    "alo.install_steps(pipeline, alo.control[\"get_asset_source\"])\n",
    "envs, args, data, config = {}, {}, {}, {}\n",
    "asset_structure = AssetStructure(envs, args, data, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff83d2d-96f6-4b76-aae2-cde768ccb459",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Input asset \n",
    "##### Input asset의 arguments 수정 및 확인\n",
    "- 필요한경우 input_args의 항목을 ***input_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd4936e-5a10-4912-9be7-b584bbd46faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'inf',\n",
       " 'x_columns': ['input_x0', 'input_x1', 'input_x2', 'input_x3'],\n",
       " 'use_all_x': False,\n",
       " 'y_column': None,\n",
       " 'groupkey_columns': None,\n",
       " 'drop_columns': None,\n",
       " 'time_column': None,\n",
       " 'concat_dataframes': True,\n",
       " 'encoding': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "step = 0 \n",
    "input_args =  alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 input_args를 원하는 값으로 수정합니다. \n",
    "# input_args['x_columns'] = ['']\n",
    "input_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ebf68-4622-431b-a458-2f6549949457",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b327df2-05c3-4538-abab-2c54bab36358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-02 09:28:08,320][USER][INFO][inference_pipeline][input]: >> Load path : ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/']\n",
      "[2023-11-02 09:28:08,331][USER][INFO][inference_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/iris.csv)\n",
      "[2023-11-02 09:28:08,334][USER][INFO][inference_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-02 09:28:08,338][USER][INFO][inference_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[2023-11-02 09:28:08,341][USER][INFO][inference_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/iris.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-02 09:28:08,315][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:28:08\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/input_data.pkl\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/input_config.pkl\n",
      "\u001b[94m[2023-11-02 09:28:08,347][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-02 09:28:08\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,350][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: input\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  input_x0  input_x1  input_x2  input_x3     target\n",
       "0         147       6.5       3.0       5.2       2.0  virginica\n",
       "1         148       6.2       3.4       5.4       2.3  virginica\n",
       "2         149       5.9       3.0       5.1       1.8  virginica"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.args = input_args # 변경한 input_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: input asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: input asset의 결과 config입니다. 다음 asset실행 시 필요합니다.\n",
    "\n",
    "# input asset의 결과 dataframe은 data_input['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed2281-711e-4284-b9ff-6f35a9577f7c",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 2. Preprocess asset \n",
    "##### Preprocess asset의 args수정 및 확인\n",
    "- 필요한경우 preprocess_args의 항목을 ***preprocess_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947687b4-7573-4557-9f39-5e87256d34f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handling_encoding_y_column': None,\n",
       " 'handling_encoding_y': None,\n",
       " 'handling_missing': 'dropna',\n",
       " 'handling_scaling_x': 'none',\n",
       " 'drop_duplicate_time': True,\n",
       " 'load_train_preprocess': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference  asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "step = 1 \n",
    "preprocess_args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess_args 수정합니다. \n",
    "# preprocess_args['handling_missing'] = 'interpolation'\n",
    "preprocess_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed3255-a09f-460c-9ea6-b2969547df81",
   "metadata": {},
   "source": [
    "##### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5cc44ca-e531-4d4b-8b36-481f10aa75e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/input_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/input_data.pkl\n",
      "\u001b[92m[2023-11-02 09:28:08,383][ASSET][INFO][inference_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,385][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:28:08\n",
      "- current step      : preprocess\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_encoding_y_column', 'handling_encoding_y', 'handling_missing', 'handling_scaling_x', 'drop_duplicate_time', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'] \n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "Saved : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "\u001b[94m[2023-11-02 09:28:08,397][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-02 09:28:08\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-02 09:28:08,399][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  input_x2  input_x3  input_x0_nan  input_x1_nan  \\\n",
       "0       6.5       3.0       5.2       2.0           6.5           3.0   \n",
       "1       6.2       3.4       5.4       2.3           6.2           3.4   \n",
       "2       5.9       3.0       5.1       1.8           5.9           3.0   \n",
       "\n",
       "   input_x2_nan  input_x3_nan  \n",
       "0           5.2           2.0  \n",
       "1           5.4           2.3  \n",
       "2           5.1           1.8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.args = preprocess_args # 변경한 preprocess_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: preprocess asset의 결과물입니다. 다음 asset 실행 시 필요합니다. \n",
    "# asset_structure.config: preprocess asset의 결과 config입니다. 다음 asset실행 시 필요합니다. \n",
    "\n",
    "# preprocess asset의 결과 dataframe은 data_preprocess['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab9a71-b432-42b5-872c-4ebf7e69eafc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3. inference asset \n",
    "##### inference asset의 args수정 및 확인\n",
    "- 필요한경우 TCR_args의 항목을 ***TCR_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7346ec19-6e57-4aab-b558-357d0e10a3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "step = 2\n",
    "tcr_args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 tcr_args를 수정합니다. \n",
    "# tcr_args['model_type'] = \n",
    "tcr_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0d59a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artifacts': {'input': '/home/jovyan/project/alo_test_20231102/tcr/alo//input/',\n",
       "  '.train_artifacts': '/home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/',\n",
       "  '.inference_artifacts': '/home/jovyan/project/alo_test_20231102/tcr/alo//.inference_artifacts/',\n",
       "  '.asset_interface': '/home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/',\n",
       "  '.history': '/home/jovyan/project/alo_test_20231102/tcr/alo//.history/'},\n",
       " 'pipeline': 'inference_pipeline',\n",
       " 'data_source_type': 'batch',\n",
       " 'time_format': '%Y-%m-%dT%H:%M:%S',\n",
       " 'time_column': '',\n",
       " 'x_columns': ['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'],\n",
       " 'input_path': ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/'],\n",
       " 'group_cnt': 0,\n",
       " 'group_keys': [],\n",
       " 'y_column': '',\n",
       " 'input_asset_df_path': {'dataframe': ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/iris.csv']},\n",
       " 'ignore_columns': ['input_x1', 'input_x0', 'input_x2', 'input_x3'],\n",
       " 'columns_map': {'input_x0_nan': 'input_x0',\n",
       "  'input_x1_nan': 'input_x1',\n",
       "  'input_x2_nan': 'input_x2',\n",
       "  'input_x3_nan': 'input_x3'},\n",
       " 'preprocess': {'handling_encoding_y_column': None,\n",
       "  'handling_encoding_y': None,\n",
       "  'handling_missing': 'dropna',\n",
       "  'handling_scaling_x': 'none',\n",
       "  'drop_duplicate_time': True,\n",
       "  'load_train_preprocess': True}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0704f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artifacts': {'input': '/home/jovyan/project/alo_test_20231102/tcr/alo//input/',\n",
       "  '.train_artifacts': '/home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/',\n",
       "  '.inference_artifacts': '/home/jovyan/project/alo_test_20231102/tcr/alo//.inference_artifacts/',\n",
       "  '.asset_interface': '/home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/',\n",
       "  '.history': '/home/jovyan/project/alo_test_20231102/tcr/alo//.history/'},\n",
       " 'pipeline': 'inference_pipeline',\n",
       " 'data_source_type': 'batch',\n",
       " 'time_format': '%Y-%m-%dT%H:%M:%S',\n",
       " 'time_column': '',\n",
       " 'x_columns': ['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'],\n",
       " 'input_path': ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/'],\n",
       " 'group_cnt': 0,\n",
       " 'group_keys': [],\n",
       " 'y_column': '',\n",
       " 'input_asset_df_path': {'dataframe': ['/home/jovyan/project/alo_test_20231102/tcr/alo//input/inf/iris.csv']},\n",
       " 'ignore_columns': ['input_x1', 'input_x0', 'input_x2', 'input_x3'],\n",
       " 'columns_map': {'input_x0_nan': 'input_x0',\n",
       "  'input_x1_nan': 'input_x1',\n",
       "  'input_x2_nan': 'input_x2',\n",
       "  'input_x3_nan': 'input_x3'},\n",
       " 'preprocess': {'handling_encoding_y_column': None,\n",
       "  'handling_encoding_y': None,\n",
       "  'handling_missing': 'dropna',\n",
       "  'handling_scaling_x': 'none',\n",
       "  'drop_duplicate_time': True,\n",
       "  'load_train_preprocess': True}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_structure.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79326071-d505-4ed2-9f8b-a4fbdad14f02",
   "metadata": {},
   "source": [
    "##### inference asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90de8db-0682-4c6e-b2e7-60a5dd6024fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_test_20231102/tcr/alo//.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "\n",
      " ################################### inference_init (sec):  0.0033044815063476562 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-02 09:28:08,459][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-02 09:28:08\n",
      "- current step      : inference\n",
      "- asset branch.     : tcr_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type'])\n",
      "- load config. keys : dict_keys(['artifacts', 'pipeline', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:08,462][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-02 09:28:08,464][ASSET][INFO][inference_pipeline][inference]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_test_20231102/tcr/alo//.inference_artifacts/output/inference/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['input_x1', 'input_x0', 'input_x2', 'input_x3'])\n",
      "[INFO] XAI 분석 시, 활용할 모델을 로드합니다.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n\n============================= ASSET ERROR =============================\nTIME(UTC)   : 2023-11-02 09:28:08,471\nPIPELINE    : inference_pipeline\nSTEP        : inference\nERROR(msg)  : model_selection.json 파일은 로드 되었으나, 데이터에 모델 추론에 필요한 칼럼이 포함되어 있지 않습니다.                 XAI 단계에 입력된 데이터 및 X_columns 에 ( [] ) 칼럼(들)이 포함되어 있는지 확인하세요.\n=======================================================================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/tcr/lib/python3.10/site-packages/alolib/asset.py:468\u001b[0m, in \u001b[0;36mAsset.decorator_run.<locals>._run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# run user asset \u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# save_data, save_config 호출은 step 당 1회 제한 (안그러면 덮어씌워짐)\u001b[39;00m\n",
      "File \u001b[0;32m~/project/alo_test_20231102/tcr/alo/assets/inference/asset_inference.py:224\u001b[0m, in \u001b[0;36mUserAsset.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m tcr\u001b[38;5;241m.\u001b[39mpath_inference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path\n\u001b[0;32m--> 224\u001b[0m out_df \u001b[38;5;241m=\u001b[39m \u001b[43mtcr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 어짜피 shapely 하더라도 이걸 먼저 해야 set data 되므로 X_test 생김 (@tcr.py)\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_column \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_column \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/project/alo_test_20231102/tcr/alo/assets/inference/tcr.py:769\u001b[0m, in \u001b[0;36mTCR.inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m     error_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(model_log_features_tuple) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(x_numbering_map_tuple) \u001b[38;5;66;03m#set(self.x)\u001b[39;00m\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrols\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_model_log\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 파일은 로드 되었으나, 데이터에 모델 추론에 필요한 칼럼이 포함되어 있지 않습니다. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124m        XAI 단계에 입력된 데이터 및 X_columns 에 ( \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(error_col)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ) 칼럼(들)이 포함되어 있는지 확인하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;66;03m## regression / classification 방식이 train & inference 가 서로 다르다면 에러 발생\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: model_selection.json 파일은 로드 되었으나, 데이터에 모델 추론에 필요한 칼럼이 포함되어 있지 않습니다.                 XAI 단계에 입력된 데이터 및 X_columns 에 ( [] ) 칼럼(들)이 포함되어 있는지 확인하세요.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m asset_structure\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m tcr_args \u001b[38;5;66;03m# 변경한 preprocess_args 반영\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m asset_structure \u001b[38;5;241m=\u001b[39m \u001b[43malo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_asset_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43malo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masset_source\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masset_structure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# asset_structure.data: TCR asset의 결과물입니다. \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# asset_structure.args: TCR asset의 결과 config입니다. \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# tcr asset의 결과 dataframe은 data_tcr['dataframe']으로 확인할 수 있습니다. \u001b[39;00m\n\u001b[1;32m      7\u001b[0m asset_structure\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m) \n",
      "File \u001b[0;32m~/project/alo_test_20231102/tcr/alo/src/alo.py:188\u001b[0m, in \u001b[0;36mALO.process_asset_step\u001b[0;34m(self, asset_config, step, pipeline, asset_structure)\u001b[0m\n\u001b[1;32m    185\u001b[0m asset_structure\u001b[38;5;241m.\u001b[39menvs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterface_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterface_mode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    187\u001b[0m ua \u001b[38;5;241m=\u001b[39m user_asset(asset_structure) \n\u001b[0;32m--> 188\u001b[0m asset_structure\u001b[38;5;241m.\u001b[39mdata, asset_structure\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m \u001b[43mua\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# FIXME memory release : on/off 필요 \u001b[39;00m\n\u001b[1;32m    191\u001b[0m release(_path)\n",
      "File \u001b[0;32m~/conda/envs/tcr/lib/python3.10/site-packages/alolib/asset.py:478\u001b[0m, in \u001b[0;36mAsset.decorator_run.<locals>._run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39masset_error(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should make dict for argument of << self.asset.save_data()>> or << self.asset.save_config() >> \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m @ << \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m >> step.\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 478\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masset_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# print asset finish info.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asset_finish_info()\n",
      "File \u001b[0;32m~/conda/envs/tcr/lib/python3.10/site-packages/alolib/logger.py:350\u001b[0m, in \u001b[0;36mLogger.asset_error\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    347\u001b[0m error_logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    348\u001b[0m error_logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(formatted_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: \n\n============================= ASSET ERROR =============================\nTIME(UTC)   : 2023-11-02 09:28:08,471\nPIPELINE    : inference_pipeline\nSTEP        : inference\nERROR(msg)  : model_selection.json 파일은 로드 되었으나, 데이터에 모델 추론에 필요한 칼럼이 포함되어 있지 않습니다.                 XAI 단계에 입력된 데이터 및 X_columns 에 ( [] ) 칼럼(들)이 포함되어 있는지 확인하세요.\n=======================================================================\n\n"
     ]
    }
   ],
   "source": [
    "asset_structure.args = tcr_args # 변경한 preprocess_args 반영\n",
    "asset_structure = alo.process_asset_step(alo.asset_source[pipeline][step], step, pipeline, asset_structure)\n",
    "# asset_structure.data: TCR asset의 결과물입니다. \n",
    "# asset_structure.config: TCR asset의 결과 config입니다. \n",
    "\n",
    "# tcr asset의 결과 dataframe은 data_tcr['dataframe']으로 확인할 수 있습니다. \n",
    "asset_structure.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ce7f7-0ec3-42af-b5d9-fd1f8b32b0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
