{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba95bf5",
   "metadata": {},
   "source": [
    "# Welcome to Tabular Classification/Regression\n",
    "\n",
    "## This is the instruction for advanced user of Tabular classification/regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921781c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapping import Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d54b5fd",
   "metadata": {},
   "source": [
    "아래는 ALO 기본 설정 및 라이브러리 설치 코드입니다. 설치 에러가 발생하면 아래 셀을 재실행 하고, 지속적으로 문제가 있을 시 문의바랍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ce91a6-d23b-4631-92a2-12e15b1b328f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8613866c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 07:03:01,130][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,134][PROCESS][INFO]:  Skip loading external data. << /nas001/users/yoonji.suh/tcr_test_20231016/train_multiclass/ >> \n",
      " << train_multiclass >> already exists in << /home/jovyan/project/alo_dev/tcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,184][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,198][PROCESS][INFO]: << input >> asset had already been created at 2023-11-08 01:28:00.751822\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,202][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,230][PROCESS][INFO]: << preprocess >> asset had already been created at 2023-11-08 01:28:02.002831\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,234][PROCESS][INFO]: Start setting-up << sampling >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,253][PROCESS][INFO]: << sampling >> asset had already been created at 2023-11-08 01:28:04.169848\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,255][PROCESS][INFO]: Start setting-up << train >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,269][PROCESS][INFO]: << train >> asset had already been created at 2023-11-08 01:28:09.861891\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,314][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,318][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,321][PROCESS][INFO]: >>> Ignored installing << numpy==1.25.2 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,325][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,328][PROCESS][INFO]: >>> Ignored installing << scikit-learn >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,331][PROCESS][INFO]: >>> Ignored installing << matplotlib >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,334][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,337][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,341][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,343][PROCESS][INFO]: ======================================== Start dependency installation : << preprocess >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,346][PROCESS][INFO]: Start checking existence & installing package - category_encoders | Progress: ( 2 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,349][PROCESS][INFO]: [OK] << category_encoders >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,351][PROCESS][INFO]: ======================================== Start dependency installation : << sampling >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,354][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 | Progress: ( 3 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,356][PROCESS][INFO]: [OK] << numpy==1.25.2 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,358][PROCESS][INFO]: Start checking existence & installing package - scikit-learn | Progress: ( 4 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,361][PROCESS][INFO]: [OK] << scikit-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,364][PROCESS][INFO]: Start checking existence & installing package - umap-learn | Progress: ( 5 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,367][PROCESS][INFO]: [OK] << umap-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,369][PROCESS][INFO]: Start checking existence & installing package - matplotlib | Progress: ( 6 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,373][PROCESS][INFO]: [OK] << matplotlib >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,375][PROCESS][INFO]: ======================================== Start dependency installation : << train >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,378][PROCESS][INFO]: Start checking existence & installing package - seaborn | Progress: ( 7 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,382][PROCESS][INFO]: [OK] << seaborn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,385][PROCESS][INFO]: Start checking existence & installing package - shap | Progress: ( 8 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,389][PROCESS][INFO]: [OK] << shap >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,391][PROCESS][INFO]: Start checking existence & installing package - lightgbm | Progress: ( 9 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,394][PROCESS][INFO]: [OK] << lightgbm >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,396][PROCESS][INFO]: Start checking existence & installing package - catboost | Progress: ( 10 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,399][PROCESS][INFO]: [OK] << catboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,401][PROCESS][INFO]: Start checking existence & installing package - ngboost | Progress: ( 11 / 12 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:01,404][PROCESS][INFO]: [OK] << ngboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,407][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,409][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 --force-reinstall | Progress: ( 12 / 12 total packages ) \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:01,412][PROCESS][INFO]: >>> Start installing package - numpy==1.25.2 --force-reinstall\u001b[0m\n",
      "Collecting numpy==1.25.2\n",
      "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/jovyan/conda/envs/tcr/lib/python3.10/site-packages/~6mpy.libs'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/jovyan/conda/envs/tcr/lib/python3.10/site-packages/~6mpy'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed numpy-1.25.2\n",
      "\u001b[94m[2023-11-08 07:03:22,764][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Train 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "wrapper = Wrapper(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3445157",
   "metadata": {},
   "source": [
    "### 본 문서는 TCR train asset에 대한 활용 가이드입니다.\n",
    "\n",
    "### input(step=0)~sampling(step=2)까지 한 번에 실행합니다.\n",
    "### step을 별도 입력하지 않아도 run method 내부에서 알아서 다음 step으로 넘어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e314fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-08 07:03:22,819][USER][INFO][train_pipeline][input]: >> Load path : ['/home/jovyan/project/alo_dev/tcr/alo//input/train_multiclass/']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 07:03:22,815][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:03:22\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_2.0\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-08 07:03:22,843][USER][INFO][train_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/project/alo_dev/tcr/alo//input/train_multiclass/iris.csv)\n",
      "[2023-11-08 07:03:22,847][USER][INFO][train_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-08 07:03:22,851][USER][INFO][train_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[2023-11-08 07:03:22,855][USER][INFO][train_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/project/alo_dev/tcr/alo//input/train_multiclass/iris.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_config.pkl\n",
      "\u001b[94m[2023-11-08 07:03:22,873][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:03:22\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:22,875][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: input\u001b[0m\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/input_data.pkl\n",
      "\u001b[92m[2023-11-08 07:03:22,921][ASSET][INFO][train_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:22,924][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:03:22\n",
      "- current step      : preprocess\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_encoding_y_column', 'handling_encoding_y', 'handling_missing', 'handling_scaling_x', 'drop_duplicate_time', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "target column : label Encoder saved : /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/preprocess/\n",
      "['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'] target_encoded_nan\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_config.pkl\n",
      "\u001b[94m[2023-11-08 07:03:22,963][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:03:22\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:22,965][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: preprocess\u001b[0m\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/preprocess_data.pkl\n",
      "\u001b[94m[2023-11-08 07:03:22,972][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:03:22\n",
      "- current step      : sampling\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['sampling_type', 'sampling_method', 'label_sampling', 'ignore_label_class', 'negative_target_class', 'label_sampling_num_type', 'label_sampling_num', 'sampling_groupkey_columns', 'sampling_num_type', 'sampling_num'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:22,975][ASSET][INFO][train_pipeline][sampling]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/sampling/\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_config.pkl\n",
      "\u001b[94m[2023-11-08 07:03:22,979][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:03:22\n",
      "- current step      : sampling\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:22,980][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: sampling\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "## input asset\n",
    "wrapper.run()\n",
    "\n",
    "## preprocess asset\n",
    "wrapper.run()\n",
    "\n",
    "## sampling asset\n",
    "wrapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24997c79-babb-4445-b1ff-e2493dfdaad6",
   "metadata": {},
   "source": [
    "### train asset args 변경하기\n",
    "\n",
    "##### train asset의 args수정 및 확인\n",
    "\n",
    "- 필요한경우 TCR_args의 항목을 ***TCR_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e0840b-50ba-4f6b-8998-8b28a5bfd5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification',\n",
       " 'data_split_method': 'cross_validate',\n",
       " 'evaluation_metric': 'accuracy',\n",
       " 'model_list': ['lgb', 'rf', 'cb'],\n",
       " 'num_hpo': 3,\n",
       " 'param_range': {'rf': {'max_depth': 6, 'n_estimators': [300, 500]},\n",
       "  'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "  'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "  'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "  'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}},\n",
       " 'shap_ratio': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR train asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - sampling(2) - train(3))\n",
    "tcr_args = wrapper.get_args(step=3)\n",
    "\n",
    "# 아래 주석을 풀어 tcr_args를 수정합니다. \n",
    "# tcr_args['model_list'] = ['lgb']\n",
    "tcr_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b82f1c",
   "metadata": {},
   "source": [
    "### arguments explanation\n",
    "\n",
    "|args|explanation|default|example|data type|necessary|\n",
    "|---|---|---|---|---|---|\n",
    "|model_type|a type of problem|`classification`|`classification, regression`|str|yes|\n",
    "|data_split_method|data splitting method for train/validation dataset|`cross_validate`|`cross_validate, train_test_split`|str|no|\n",
    "|evaluation_metric|evaluation metric|`accuracy`|`accuracy, f1-score, recall, precision, mse, r2, mae, rmse`|str|yes|\n",
    "|model_list|HPO candidate ML model list|`[lgb, rf, cb]`|`[lgb, rf, cb, gbm, ngb]`|list|yes|\n",
    "|num_hpo|number of hyperparameter setting options|`3`|`0 ~ 10`|int|no|\n",
    "|param_range|range of hyperparameters for each ML model|(see below)|(see as follows)|dict|no|\n",
    "|shap_ratio|sampling rate of training dataset for shapley value calculation|`1`|`0~1`|float|no|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01173fd",
   "metadata": {},
   "source": [
    "### A. Select a type of problem: regression or classification\n",
    "\n",
    "If you have a numeric target data, such as quantity of product, temperature, polulation etc., your problem is a regression. Otherwise, if you have a categorical target data, your problem will be a classification.\n",
    "\n",
    "#### model_type: regression\n",
    "\n",
    "- model_type: regression\n",
    "- evaluation_meric: 과제/데이터 성격에 맞는 옵션 설정\n",
    "    - mse: mean squared error\n",
    "    - r2: Coefficient of determination\n",
    "    - mae: mean absolute error\n",
    "    - rmse: root mean squared error\n",
    "\n",
    "- model_list: \\[lgb, rf, cb, gbm, ngb\\] 중 학습하고 싶은 모델 선택\n",
    "    - lgb: lightGBM\n",
    "    - rf: Random Forest\n",
    "    - cb: CatBoost\n",
    "    - gbm: Gradient Boosting\n",
    "    - ngb: Natural Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1ead6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_args['model_type'] = 'regression'\n",
    "tcr_args['evaluation_meric'] = 'mse'\n",
    "tcr_args['model_list'] = ['lgb', 'rf', 'cb', 'gbm', 'ngb']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e4201",
   "metadata": {},
   "source": [
    "#### model_type: classification\n",
    "\n",
    "- model_type: classification\n",
    "- evaluation_meric: 과제/데이터 성격에 맞는 옵션 설정\n",
    "    - accuracy\n",
    "    - f1-score\n",
    "    - recall\n",
    "    - precision\n",
    "- model_list: \\[lgb, rf, cb, gbm(support binary only) \\] 중 학습하고 싶은 모델 선택\n",
    "    - lgb: lightGBM\n",
    "    - rf: Random Forest\n",
    "    - cb: CatBoost\n",
    "    - gbm: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816dc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_args['model_type'] = 'classification'\n",
    "tcr_args['evaluation_meric'] = 'accuracy'\n",
    "tcr_args['model_list'] = ['lgb', 'rf', 'cb']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35a36",
   "metadata": {},
   "source": [
    "### B. Select data splitting method: train_test_split or cross_validate\n",
    "\n",
    "Resource Usage and Performance Trade-offs for Machine Learning. If you have limited resource, then you can split just once training/validattion dataset by selecting `train_test_split` option. If you have enough resource, K-fold cross validation prevent over/under estimation of trained model so we recommend `cross_validate` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0a2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tcr_args['data_split_method'] = 'train_test_split'\n",
    "tcr_args['data_split_method'] = 'cross_validate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6f62b",
   "metadata": {},
   "source": [
    "### C. Customize Hyperparameter Optimization\n",
    "\n",
    "If you are professional to customize hyperparameter of each machine learning models, you may change default hyperparameter settings. Usually, higher value of n_estimators and max_depth increases model complexity and training time. If you exclude some model in `model_list`, corresponding model's setting in `param_range` will be ignored. Overall hyperparameter min-max range will split into `num_hpo` parameter options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da776ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting about gbm, ngb will be ignored\n",
    "tcr_args['num_hpo'] = 5\n",
    "tcr_args['param_range'] = {\n",
    "    'rf': {'max_depth': 6, 'n_estimators': [100, 500]},\n",
    "    'gbm': {'max_depth': [5, 9], 'n_estimators': [100, 500]},\n",
    "    'ngb': {'col_sample': [0.4, 0.9], 'n_estimators': [100, 500]},\n",
    "    'lgb': {'max_depth': [5, 9], 'n_estimators': [100, 500]},\n",
    "    'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}}\n",
    "\n",
    "# in this case, rf's optimizing n_estimator options will be 100, 200, 300, 400, 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd1409",
   "metadata": {},
   "source": [
    "### D. Set shapley_ratio\n",
    "\n",
    "Calculating shapley value takes some time. If you don't need shapley value for training data or you only need estimated shapley value, then you can save calculating time by reducing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee83df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tcr_args['shap_ratio'] = 0.5\n",
    "tcr_args['shap_ratio'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29407e1f-58b2-4c97-b58a-6d684ad47167",
   "metadata": {},
   "source": [
    "##### train asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e964dac8-836a-4b4c-b2b1-d183377d4068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/sampling_data.pkl\n",
      "\u001b[92m[2023-11-08 07:03:28,928][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:28,932][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:28,933][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:03:28\n",
      "- current step      : train\n",
      "- asset branch.     : tcr_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'data_split_method', 'evaluation_metric', 'model_list', 'num_hpo', 'param_range', 'shap_ratio', 'evaluation_meric'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:28,936][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:28,938][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:03:28,940][ASSET][INFO][train_pipeline][train]: Successfully got << report path >> for saving your << report.html >> file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/report/\u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['target_encoded_nan', 'input_x2', 'input_x0', 'input_x1', 'target', 'target_encoded', 'input_x3'])\n",
      "[INFO] 모델 학습을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 0th-fold RandomForestClassifier_set0 모델을 학습합니다.(1/60)\n",
      "[INFO] 1th-fold RandomForestClassifier_set0 모델을 학습합니다.(2/60)\n",
      "[INFO] 2th-fold RandomForestClassifier_set0 모델을 학습합니다.(3/60)\n",
      "[INFO] 3th-fold RandomForestClassifier_set0 모델을 학습합니다.(4/60)\n",
      "[INFO] 0th-fold RandomForestClassifier_set1 모델을 학습합니다.(5/60)\n",
      "[INFO] 1th-fold RandomForestClassifier_set1 모델을 학습합니다.(6/60)\n",
      "[INFO] 2th-fold RandomForestClassifier_set1 모델을 학습합니다.(7/60)\n",
      "[INFO] 3th-fold RandomForestClassifier_set1 모델을 학습합니다.(8/60)\n",
      "[INFO] 0th-fold RandomForestClassifier_set2 모델을 학습합니다.(9/60)\n",
      "[INFO] 1th-fold RandomForestClassifier_set2 모델을 학습합니다.(10/60)\n",
      "[INFO] 2th-fold RandomForestClassifier_set2 모델을 학습합니다.(11/60)\n",
      "[INFO] 3th-fold RandomForestClassifier_set2 모델을 학습합니다.(12/60)\n",
      "[INFO] 0th-fold RandomForestClassifier_set3 모델을 학습합니다.(13/60)\n",
      "[INFO] 1th-fold RandomForestClassifier_set3 모델을 학습합니다.(14/60)\n",
      "[INFO] 2th-fold RandomForestClassifier_set3 모델을 학습합니다.(15/60)\n",
      "[INFO] 3th-fold RandomForestClassifier_set3 모델을 학습합니다.(16/60)\n",
      "[INFO] 0th-fold RandomForestClassifier_set4 모델을 학습합니다.(17/60)\n",
      "[INFO] 1th-fold RandomForestClassifier_set4 모델을 학습합니다.(18/60)\n",
      "[INFO] 2th-fold RandomForestClassifier_set4 모델을 학습합니다.(19/60)\n",
      "[INFO] 3th-fold RandomForestClassifier_set4 모델을 학습합니다.(20/60)\n",
      "[INFO] 0th-fold LGBMClassifier_set0 모델을 학습합니다.(21/60)\n",
      "[INFO] 1th-fold LGBMClassifier_set0 모델을 학습합니다.(22/60)\n",
      "[INFO] 2th-fold LGBMClassifier_set0 모델을 학습합니다.(23/60)\n",
      "[INFO] 3th-fold LGBMClassifier_set0 모델을 학습합니다.(24/60)\n",
      "[INFO] 0th-fold LGBMClassifier_set1 모델을 학습합니다.(25/60)\n",
      "[INFO] 1th-fold LGBMClassifier_set1 모델을 학습합니다.(26/60)\n",
      "[INFO] 2th-fold LGBMClassifier_set1 모델을 학습합니다.(27/60)\n",
      "[INFO] 3th-fold LGBMClassifier_set1 모델을 학습합니다.(28/60)\n",
      "[INFO] 0th-fold LGBMClassifier_set2 모델을 학습합니다.(29/60)\n",
      "[INFO] 1th-fold LGBMClassifier_set2 모델을 학습합니다.(30/60)\n",
      "[INFO] 2th-fold LGBMClassifier_set2 모델을 학습합니다.(31/60)\n",
      "[INFO] 3th-fold LGBMClassifier_set2 모델을 학습합니다.(32/60)\n",
      "[INFO] 0th-fold LGBMClassifier_set3 모델을 학습합니다.(33/60)\n",
      "[INFO] 1th-fold LGBMClassifier_set3 모델을 학습합니다.(34/60)\n",
      "[INFO] 2th-fold LGBMClassifier_set3 모델을 학습합니다.(35/60)\n",
      "[INFO] 3th-fold LGBMClassifier_set3 모델을 학습합니다.(36/60)\n",
      "[INFO] 0th-fold LGBMClassifier_set4 모델을 학습합니다.(37/60)\n",
      "[INFO] 1th-fold LGBMClassifier_set4 모델을 학습합니다.(38/60)\n",
      "[INFO] 2th-fold LGBMClassifier_set4 모델을 학습합니다.(39/60)\n",
      "[INFO] 3th-fold LGBMClassifier_set4 모델을 학습합니다.(40/60)\n",
      "[INFO] 0th-fold CatBoostClassifier_set0 모델을 학습합니다.(41/60)\n",
      "[INFO] 1th-fold CatBoostClassifier_set0 모델을 학습합니다.(42/60)\n",
      "[INFO] 2th-fold CatBoostClassifier_set0 모델을 학습합니다.(43/60)\n",
      "[INFO] 3th-fold CatBoostClassifier_set0 모델을 학습합니다.(44/60)\n",
      "[INFO] 0th-fold CatBoostClassifier_set1 모델을 학습합니다.(45/60)\n",
      "[INFO] 1th-fold CatBoostClassifier_set1 모델을 학습합니다.(46/60)\n",
      "[INFO] 2th-fold CatBoostClassifier_set1 모델을 학습합니다.(47/60)\n",
      "[INFO] 3th-fold CatBoostClassifier_set1 모델을 학습합니다.(48/60)\n",
      "[INFO] 0th-fold CatBoostClassifier_set2 모델을 학습합니다.(49/60)\n",
      "[INFO] 1th-fold CatBoostClassifier_set2 모델을 학습합니다.(50/60)\n",
      "[INFO] 2th-fold CatBoostClassifier_set2 모델을 학습합니다.(51/60)\n",
      "[INFO] 3th-fold CatBoostClassifier_set2 모델을 학습합니다.(52/60)\n",
      "[INFO] 0th-fold CatBoostClassifier_set3 모델을 학습합니다.(53/60)\n",
      "[INFO] 1th-fold CatBoostClassifier_set3 모델을 학습합니다.(54/60)\n",
      "[INFO] 2th-fold CatBoostClassifier_set3 모델을 학습합니다.(55/60)\n",
      "[INFO] 3th-fold CatBoostClassifier_set3 모델을 학습합니다.(56/60)\n",
      "[INFO] 0th-fold CatBoostClassifier_set4 모델을 학습합니다.(57/60)\n",
      "[INFO] 1th-fold CatBoostClassifier_set4 모델을 학습합니다.(58/60)\n",
      "[INFO] 2th-fold CatBoostClassifier_set4 모델을 학습합니다.(59/60)\n",
      "[INFO] 3th-fold CatBoostClassifier_set4 모델을 학습합니다.(60/60)\n",
      "@scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list:  @scoring_classification func. - label list: @scoring_classification func. - label list:  @scoring_classification func. - label list: @scoring_classification func. - label list: {0, 1, 2}@scoring_classification func. - label list:  @scoring_classification func. - label list:  @scoring_classification func. - label list: {0, 1, 2}@scoring_classification func. - label list:   @scoring_classification func. - label list: @scoring_classification func. - label list:  \n",
      "{0, 1, 2}  {0, 1, 2}\n",
      "@scoring_classification func. - label list:  {0, 1, 2}{0, 1, 2}@scoring_classification func. - label list: {0, 1, 2} \n",
      " {0, 1, 2}{0, 1, 2}\n",
      " {0, 1, 2} \n",
      "\n",
      "\n",
      " \n",
      "{0, 1, 2}{0, 1, 2}\n",
      "{0, 1, 2}{0, 1, 2}\n",
      "{0, 1, 2}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] 평가 지표는 ( accuracy ) 를 사용합니다. \n",
      "모델 정보 로그를 저장합니다. (저장위치: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/model_selection.json)\n",
      "\n",
      "Top 1 model file is saved: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top0.pkl\n",
      "[Score] accuracy: 0.9660\n",
      "[Hyper-parameters] max_depth: 5, n_estimators: 100, n_jobs: 1, verbose: -1, \n",
      "\n",
      "Top 2 model file is saved: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top1.pkl\n",
      "[Score] accuracy: 0.9660\n",
      "[Hyper-parameters] max_depth: 5, n_estimators: 100, verbose: 0, random_state: 1234, thread_count: 6, allow_writing_files: False, \n",
      "\n",
      "Top 3 model file is saved: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top2.pkl\n",
      "[Score] accuracy: 0.9592\n",
      "[Hyper-parameters] n_estimators: 100, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Following model is the best: LGBMClassifier_set0 / accuracy:0.9660\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[INFO] Summary_plot for Train data 를 저장했습니다.\n",
      "\n",
      "ignore columns와 X로 지정한 데이터 프레임을 합치는 과정중에 에러가 발생했습니다. 확인 부탁드립니다.\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/train_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/train_pipeline/train_config.pkl\n",
      "\u001b[94m[2023-11-08 07:03:32,411][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:03:32\n",
      "- current step      : train\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type', 'feature_dict'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:03:32,413][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "      <th>input_x0_nan_shapley</th>\n",
       "      <th>input_x1_nan_shapley</th>\n",
       "      <th>input_x2_nan_shapley</th>\n",
       "      <th>input_x3_nan_shapley</th>\n",
       "      <th>target_encoded_nan</th>\n",
       "      <th>pred_target_encoded_nan</th>\n",
       "      <th>pred_target_encoded_nan_best0</th>\n",
       "      <th>pred_target_encoded_nan_best1</th>\n",
       "      <th>pred_target_encoded_nan_best2</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.006718</td>\n",
       "      <td>-0.291241</td>\n",
       "      <td>-2.753147</td>\n",
       "      <td>-1.902588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019352</td>\n",
       "      <td>-0.652646</td>\n",
       "      <td>-2.710782</td>\n",
       "      <td>1.282438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>-0.291495</td>\n",
       "      <td>-2.729541</td>\n",
       "      <td>-1.903580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>-0.278018</td>\n",
       "      <td>-2.705974</td>\n",
       "      <td>-1.915641</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.052984</td>\n",
       "      <td>-0.573770</td>\n",
       "      <td>3.002291</td>\n",
       "      <td>-2.000413</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.993329</td>\n",
       "      <td>0.005899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>-0.251354</td>\n",
       "      <td>-2.723763</td>\n",
       "      <td>-1.933553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.037141</td>\n",
       "      <td>-0.320705</td>\n",
       "      <td>-2.760122</td>\n",
       "      <td>-1.913649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.998959</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.037141</td>\n",
       "      <td>-0.320705</td>\n",
       "      <td>-2.760122</td>\n",
       "      <td>-1.913649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.028426</td>\n",
       "      <td>0.575538</td>\n",
       "      <td>3.337348</td>\n",
       "      <td>3.681772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955328</td>\n",
       "      <td>0.044571</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.037056</td>\n",
       "      <td>-0.293366</td>\n",
       "      <td>-2.765118</td>\n",
       "      <td>-1.910030</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0_nan  input_x1_nan  input_x2_nan  input_x3_nan  \\\n",
       "0           5.7           2.8           4.1           1.3   \n",
       "1           5.0           2.3           3.3           1.0   \n",
       "2           6.5           2.8           4.6           1.5   \n",
       "3           6.3           2.9           5.6           1.8   \n",
       "4           5.1           2.5           3.0           1.1   \n",
       "5           6.6           3.0           4.4           1.4   \n",
       "6           5.5           2.5           4.0           1.3   \n",
       "7           5.5           2.3           4.0           1.3   \n",
       "8           5.1           3.8           1.9           0.4   \n",
       "9           5.2           2.7           3.9           1.4   \n",
       "\n",
       "   input_x0_nan_shapley  input_x1_nan_shapley  input_x2_nan_shapley  \\\n",
       "0             -0.006718             -0.291241             -2.753147   \n",
       "1             -0.019352             -0.652646             -2.710782   \n",
       "2              0.005979             -0.291495             -2.729541   \n",
       "3              0.006351             -0.278018             -2.705974   \n",
       "4             -0.052984             -0.573770              3.002291   \n",
       "5              0.005979             -0.251354             -2.723763   \n",
       "6             -0.037141             -0.320705             -2.760122   \n",
       "7             -0.037141             -0.320705             -2.760122   \n",
       "8             -0.028426              0.575538              3.337348   \n",
       "9             -0.037056             -0.293366             -2.765118   \n",
       "\n",
       "   input_x3_nan_shapley  target_encoded_nan  pred_target_encoded_nan  \\\n",
       "0             -1.902588                   1                        1   \n",
       "1              1.282438                   1                        1   \n",
       "2             -1.903580                   1                        1   \n",
       "3             -1.915641                   2                        2   \n",
       "4             -2.000413                   1                        1   \n",
       "5             -1.933553                   1                        1   \n",
       "6             -1.913649                   1                        1   \n",
       "7             -1.913649                   1                        1   \n",
       "8              3.681772                   0                        0   \n",
       "9             -1.910030                   1                        1   \n",
       "\n",
       "   pred_target_encoded_nan_best0  pred_target_encoded_nan_best1  \\\n",
       "0                              1                              1   \n",
       "1                              1                              1   \n",
       "2                              1                              1   \n",
       "3                              2                              2   \n",
       "4                              1                              1   \n",
       "5                              1                              1   \n",
       "6                              1                              1   \n",
       "7                              1                              1   \n",
       "8                              0                              0   \n",
       "9                              1                              1   \n",
       "\n",
       "   pred_target_encoded_nan_best2    prob_0    prob_1    prob_2  \n",
       "0                              1  0.000012  0.999582  0.000406  \n",
       "1                              1  0.001734  0.998043  0.000223  \n",
       "2                              1  0.000020  0.998906  0.001074  \n",
       "3                              2  0.000008  0.000099  0.999893  \n",
       "4                              1  0.000772  0.993329  0.005899  \n",
       "5                              1  0.000003  0.999991  0.000006  \n",
       "6                              1  0.000005  0.998959  0.001036  \n",
       "7                              1  0.000005  0.998973  0.001022  \n",
       "8                              0  0.955328  0.044571  0.000101  \n",
       "9                              1  0.000004  0.999931  0.000065  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrapper.run(args=tcr_args) # 변경한 tcr_args 반영\n",
    "# wrapper.data: TCR asset의 결과물입니다. \n",
    "# wrapper.config: TCR asset의 결과 config입니다. \n",
    "\n",
    "# tcr asset의 결과 dataframe은 wrapper.data['dataframe']으로 확인할 수 있습니다. \n",
    "wrapper.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0370-76a0-4a67-8f18-fbc0c78be45d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Inference workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c4f2ad-3672-47c4-ab90-f242351868a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 07:04:27,448][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,452][PROCESS][INFO]:  Skip loading external data. << /nas001/users/yoonji.suh/tcr_test_20231016/inf/ >> \n",
      " << inf >> already exists in << /home/jovyan/project/alo_dev/tcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,454][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,457][PROCESS][INFO]: << input >> asset had already been created at 2023-11-08 01:28:00.751822\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,460][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:04:27,463][PROCESS][INFO]: Now << local >> asset_source_code mode: <preprocess> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,466][PROCESS][INFO]: Start setting-up << inference >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,482][PROCESS][INFO]: << inference >> asset had already been created at 2023-11-08 01:28:18.350955\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,486][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,489][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,492][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,496][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 1 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-08 07:04:27,500][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,503][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,506][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Inference 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "wrapper = Wrapper(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8157999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-08 07:04:27,542][USER][INFO][inference_pipeline][input]: >> Load path : ['/home/jovyan/project/alo_dev/tcr/alo//input/inf/']\n",
      "[2023-11-08 07:04:27,557][USER][INFO][inference_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/project/alo_dev/tcr/alo//input/inf/iris.csv)\n",
      "[2023-11-08 07:04:27,561][USER][INFO][inference_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-08 07:04:27,565][USER][INFO][inference_pipeline][input]: >> Drop columns from the input dataframe when set << auto >> mode or specified in the << drop_columns >> in config yaml. (dropped colums:[])\n",
      "[2023-11-08 07:04:27,569][USER][INFO][inference_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/project/alo_dev/tcr/alo//input/inf/iris.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-08 07:04:27,524][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:04:27\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_config.pkl\n",
      "\u001b[94m[2023-11-08 07:04:27,575][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:04:27\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,578][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: input\u001b[0m\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/input_data.pkl\n",
      "\u001b[92m[2023-11-08 07:04:27,590][ASSET][INFO][inference_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,593][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:04:27\n",
      "- current step      : preprocess\n",
      "- asset branch.     : tcr\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_encoding_y_column', 'handling_encoding_y', 'handling_missing', 'handling_scaling_x', 'drop_duplicate_time', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "['input_x0_nan', 'input_x1_nan', 'input_x2_nan', 'input_x3_nan'] \n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "\u001b[94m[2023-11-08 07:04:27,608][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:04:27\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:04:27,610][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: preprocess\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TCR inference asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - train(2))\n",
    "## input asset\n",
    "wrapper.run()\n",
    "\n",
    "## preprocess asset\n",
    "wrapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab9a71-b432-42b5-872c-4ebf7e69eafc",
   "metadata": {},
   "source": [
    "### inference asset \n",
    "##### inference asset의 args수정 및 확인\n",
    "- 필요한경우 TCR_args의 항목을 ***TCR_args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7346ec19-6e57-4aab-b558-357d0e10a3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification', 'run_shapley': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TCR inference asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2))\n",
    "tcr_args = wrapper.get_args(step=2)\n",
    "\n",
    "# 아래 주석을 풀어 tcr_args를 수정합니다. \n",
    "# tcr_args['model_type'] = \n",
    "tcr_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244cc4c",
   "metadata": {},
   "source": [
    "### arguments explanation\n",
    "\n",
    "- model_type: Select same option as training workflow's\n",
    "- run_shapley: Calcualte shapley value for inference data or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79326071-d505-4ed2-9f8b-a4fbdad14f02",
   "metadata": {},
   "source": [
    "##### inference asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90de8db-0682-4c6e-b2e7-60a5dd6024fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_config.pkl\n",
      "Loaded : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/preprocess_data.pkl\n",
      "\n",
      " ################################### inference_init (sec):  0.005219221115112305 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-08 07:07:13,774][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-08 07:07:13\n",
      "- current step      : inference\n",
      "- asset branch.     : tcr_dev\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'run_shapley'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:07:13,780][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-08 07:07:13,811][ASSET][INFO][inference_pipeline][inference]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.inference_artifacts/output/inference/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['input_x1', 'input_x2', 'input_x0', 'input_x3'])\n",
      "\u001b[92m[2023-11-08 07:07:13,818][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "[INFO] XAI 분석 시, 활용할 모델을 로드합니다.\n",
      "/home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/model_selection.json\n",
      "[['x0', 'input_x0_nan'], ['x1', 'input_x1_nan'], ['x2', 'input_x2_nan'], ['x3', 'input_x3_nan']]\n",
      "[['x0', 'input_x0_nan'], ['x1', 'input_x1_nan'], ['x2', 'input_x2_nan'], ['x3', 'input_x3_nan']]\n",
      "모델을 Load 완료 하였습니다. (모델 위치: /home/jovyan/project/alo_dev/tcr/alo//.train_artifacts/models/train/best_model_top0.pkl)\n",
      "[INFO] SHAP 기반 XAI 분석을 진행합니다.\n",
      "[INFO] Summary_plot for Inference data 를 저장했습니다. (1/2)\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/inference_data.pkl\n",
      "Saved : /home/jovyan/project/alo_dev/tcr/alo//.asset_interface/inference_pipeline/inference_config.pkl\n",
      "\n",
      " ################################### inference_user_run (sec):  0.43395137786865234 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-08 07:07:14,248][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-08 07:07:14\n",
      "- current step      : inference\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-08 07:07:14,249][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: inference\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_x0</th>\n",
       "      <th>input_x1</th>\n",
       "      <th>input_x2</th>\n",
       "      <th>input_x3</th>\n",
       "      <th>input_x0_nan</th>\n",
       "      <th>input_x1_nan</th>\n",
       "      <th>input_x2_nan</th>\n",
       "      <th>input_x3_nan</th>\n",
       "      <th>input_x0_nan_shapley</th>\n",
       "      <th>input_x1_nan_shapley</th>\n",
       "      <th>input_x2_nan_shapley</th>\n",
       "      <th>input_x3_nan_shapley</th>\n",
       "      <th>pred_</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>-0.251683</td>\n",
       "      <td>-2.705324</td>\n",
       "      <td>-1.937523</td>\n",
       "      <td>2</td>\n",
       "      <td>[3.214469212426002e-06, 7.042634647667956e-05,...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.428361</td>\n",
       "      <td>-2.798520</td>\n",
       "      <td>-2.036754</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.7515202988130232e-05, 0.000218426597621348,...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.999764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>-0.252079</td>\n",
       "      <td>-2.733928</td>\n",
       "      <td>-1.948715</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0001411818281975359, 0.04163468080437577, 0...</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.958224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_x0  input_x1  input_x2  input_x3  input_x0_nan  input_x1_nan  \\\n",
       "0       6.5       3.0       5.2       2.0           6.5           3.0   \n",
       "1       6.2       3.4       5.4       2.3           6.2           3.4   \n",
       "2       5.9       3.0       5.1       1.8           5.9           3.0   \n",
       "\n",
       "   input_x2_nan  input_x3_nan  input_x0_nan_shapley  input_x1_nan_shapley  \\\n",
       "0           5.2           2.0              0.006335             -0.251683   \n",
       "1           5.4           2.3              0.005062              0.428361   \n",
       "2           5.1           1.8             -0.000407             -0.252079   \n",
       "\n",
       "   input_x2_nan_shapley  input_x3_nan_shapley  pred_  \\\n",
       "0             -2.705324             -1.937523      2   \n",
       "1             -2.798520             -2.036754      2   \n",
       "2             -2.733928             -1.948715      2   \n",
       "\n",
       "                                    prediction_score    prob_0    prob_1  \\\n",
       "0  [3.214469212426002e-06, 7.042634647667956e-05,...  0.000003  0.000070   \n",
       "1  [1.7515202988130232e-05, 0.000218426597621348,...  0.000018  0.000218   \n",
       "2  [0.0001411818281975359, 0.04163468080437577, 0...  0.000141  0.041635   \n",
       "\n",
       "     prob_2  \n",
       "0  0.999926  \n",
       "1  0.999764  \n",
       "2  0.958224  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2700x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrapper.run(args=tcr_args) # 변경한 preprocess_args 반영\n",
    "# wrapper.data: TCR asset의 결과물입니다. \n",
    "# wrapper.config: TCR asset의 결과 config입니다. \n",
    "\n",
    "# tcr asset의 결과 dataframe은 wrapper.data['dataframe']으로 확인할 수 있습니다. \n",
    "wrapper.data['dataframe'].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ce7f7-0ec3-42af-b5d9-fd1f8b32b0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr",
   "language": "python",
   "name": "tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
